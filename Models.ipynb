{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Waiting Times Report.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"jtYPY5ERX_6C"},"source":["import pandas as pd \n","import io\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","from datetime import date, time, datetime\n","from google.colab import drive\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hv9ZX3L4MYWk"},"source":["# Emergency Department Waiting Times "]},{"cell_type":"markdown","metadata":{"id":"ze-KqjTstvM5"},"source":["### Data Upload"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"id":"4W4F8rdwXLzr","executionInfo":{"status":"ok","timestamp":1617556364050,"user_tz":360,"elapsed":80266,"user":{"displayName":"Sim Bhattarai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpaBPF0DuLN5KkInccG6Ttqk5D8haa72YxXR_6=s64","userId":"11084487050159240062"}},"outputId":"e71d55d1-9992-42b1-8a1e-1a57ff12382a"},"source":["uploaded = files.upload()\n","df = pd.read_csv(io.BytesIO(uploaded['CleanedData-withAge-Total.csv']))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-9379a2e9-33bb-4eef-bc20-8a72cf356b0b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-9379a2e9-33bb-4eef-bc20-8a72cf356b0b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving CleanedData-withAge-Total.csv to CleanedData-withAge-Total.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u1JR88Ayt0Et"},"source":["### Data Clean Up\n","\n","Helper functions to clean up Dataset, split into test and train, and function calls"]},{"cell_type":"code","metadata":{"id":"cqUYlFYRpPOg"},"source":["def cleanDataset(myData):\n","    myData.drop(index=myData[myData['CTAS_1.0'] == 1].index, inplace=True)\n","    myData.drop(index=myData[myData['CTAS_2.0'] == 1].index, inplace=True)\n","    myData = myData.drop([\"CTAS_3.0\",\"CTAS_2.0\",\"CTAS_1.0\",\"CTAS_4.0\",\"CTAS_5.0\",\"PTN_SEX_U\"],axis=1)\n","    myData = myData.dropna()\n","    for col in list(myData.columns):\n","        myList=[]\n","        myList.append(col)\n","        myData[myList] = myData[myList].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n","    return myData"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSRTFfD0qvhE"},"source":["def splitIntoTrainTest(myData):\n","    Xtrain, Xtest = train_test_split(myData, test_size=0.2)\n","    yTrain = Xtrain[\"Total_Time_Benchmark\"]\n","    del Xtrain[\"Total_Time_Benchmark\"]\n","\n","    yTest = Xtest[\"Total_Time_Benchmark\"]\n","    del Xtest[\"Total_Time_Benchmark\"]\n","    return Xtrain, Xtest, yTrain, yTest"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AX7T_FKdfj9x"},"source":["myData = cleanDataset(df)\n","Xtrain, Xtest, yTrain, yTest = splitIntoTrainTest(myData)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6KvXLoRuqTN"},"source":["### Support Vector Machine Classifiers"]},{"cell_type":"code","metadata":{"id":"VCbVnZP9de9E"},"source":["def trainSVM(Xtrain, Xtest, yTrain, yTest, k):\n","    clf = svm.SVC(kernel=k,random_state=0,class_weight='balanced')\n","    clf.fit(Xtrain,yTrain)\n","    y_pred = clf.predict(Xtest)\n","    print(\"Accuracy:\", accuracy_score(yTest, y_pred))\n","    print(\"Recall:\", precision_score(yTest, y_pred))\n","    print(\"Specificity:\", recall_score(yTest, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UL2nWLN1qkkp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617503174566,"user_tz":360,"elapsed":147016,"user":{"displayName":"Sim Bhattarai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpaBPF0DuLN5KkInccG6Ttqk5D8haa72YxXR_6=s64","userId":"11084487050159240062"}},"outputId":"e1c6688f-d1c9-4bb7-a5cc-c03431769c50"},"source":["trainSVM(Xtrain, Xtest, yTrain, yTest, 'linear')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done Training\n","Accuracy: 0.6670949780490416\n","Recall: 0.5825786977145321\n","Specificity: 0.6972903225806452\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xaz9PrPHreFR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617503605612,"user_tz":360,"elapsed":136834,"user":{"displayName":"Sim Bhattarai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpaBPF0DuLN5KkInccG6Ttqk5D8haa72YxXR_6=s64","userId":"11084487050159240062"}},"outputId":"1a9fb15f-bb83-4552-8d00-62d93b2ed638"},"source":["trainSVM(Xtrain, Xtest, yTrain, yTest, 'poly')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done Training\n","Accuracy: 0.7141021522646964\n","Recall: 0.642806352216165\n","Specificity: 0.6998709677419355\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_z_8e21brfZC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617503462711,"user_tz":360,"elapsed":210550,"user":{"displayName":"Sim Bhattarai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpaBPF0DuLN5KkInccG6Ttqk5D8haa72YxXR_6=s64","userId":"11084487050159240062"}},"outputId":"246d4c88-bc85-4dfb-e232-80d7e12040b5"},"source":["trainSVM(Xtrain, Xtest, yTrain, yTest, 'rbf')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done Training\n","Accuracy: 0.7120676731984152\n","Recall: 0.642274472168906\n","Specificity: 0.6908387096774193\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Q_0XmqovED_"},"source":["### Random Forest Classifier"]},{"cell_type":"code","metadata":{"id":"w8caDNT5usEf"},"source":["def trainRF(Xtrain, Xtest, yTrain, yTest):\n","    clf=RandomForestClassifier(random_state = 42,class_weight='balanced')#class_weight='balanced'\n","    clf.fit(Xtrain,yTrain)\n","    y_pred = clf.predict(Xtest)\n","    print(\"Accuracy:\", accuracy_score(yTest, y_pred))\n","    print(\"Recall:\", precision_score(yTest, y_pred))\n","    print(\"Specificity:\", recall_score(yTest, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DSS1Bfelvnw-","executionInfo":{"status":"ok","timestamp":1617503984365,"user_tz":360,"elapsed":6732,"user":{"displayName":"Sim Bhattarai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpaBPF0DuLN5KkInccG6Ttqk5D8haa72YxXR_6=s64","userId":"11084487050159240062"}},"outputId":"ec053858-e582-4e8d-d554-0082f37922b4"},"source":["trainRF(Xtrain, Xtest, yTrain, yTest)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done Training\n","Accuracy: 0.7230966912945711\n","Recall: 0.7069020866773675\n","Specificity: 0.568258064516129\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AUeqprVtvcUJ"},"source":["### Decision Tree For Feature Selection"]},{"cell_type":"code","metadata":{"id":"K6F62vYdwJxK"},"source":["def trainDT(Xtrain, Xtest, yTrain, yTest):\n","    clf=DecisionTreeClassifier(class_weight='balanced')\n","    clf.fit(Xtrain,yTrain)\n","    y_pred = clf.predict(Xtest)\n","    print(\"Accuracy:\", accuracy_score(yTest, y_pred))\n","    print(\"Recall:\", precision_score(yTest, y_pred))\n","    print(\"Specificity:\", recall_score(yTest, y_pred))\n","    myList=[]\n","    myList.extend(Xtrain.columns)\n","    print(myList)\n","    coefs_with_fns = sorted(zip(clf.feature_importances_, myList))\n","    df = pd.DataFrame(coefs_with_fns)\n","    df.columns = 'Coefficient', 'Feature'\n","    df.sort_values(by='coefficient')\n","    print(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8rWogndwh3Q","executionInfo":{"status":"ok","timestamp":1617504207500,"user_tz":360,"elapsed":892,"user":{"displayName":"Sim Bhattarai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpaBPF0DuLN5KkInccG6Ttqk5D8haa72YxXR_6=s64","userId":"11084487050159240062"}},"outputId":"61c15655-24a0-45f4-c2e4-6268a341ed6d"},"source":["trainDT(Xtrain, Xtest, yTrain, yTest)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done Training\n","Accuracy: 0.6376485705107613\n","Recall: 0.5630619059851014\n","Specificity: 0.5656774193548387\n","['ARRIVAL_MODE_Air Ambulance', 'ARRIVAL_MODE_Ground Ambulance', 'ARRIVAL_MODE_No Ambulance', 'INIT_TREAT_LOC_GRP_Intake', 'INIT_TREAT_LOC_GRP_MET', 'INIT_TREAT_LOC_GRP_Main', 'INIT_LOC_GRP_Intake', 'INIT_LOC_GRP_MET', 'INIT_LOC_GRP_Main', 'INIT_LOC_GRP_WR Intake', 'INIT_LOC_GRP_WR MET', 'INIT_LOC_GRP_WR Main', 'INIT_LOC_GRP_WR Non ED', 'Number_of_Patients_In_Waiting_Before', 'Number_of_Patients_In_Waiting_Before_CTAS', 'Number_of_Patients_In_Waiting_After', 'Number_of_Patients_In_Waiting_After_CTAS', 'Number_of_Patients_Waiting_For_Discharge', 'Number_of_Patients_Waiting_For_Discharge_CTAS', 'Number_of_Patients_Waiting_For_Admission', 'Number_of_Patients_Waiting_For_Admission_CTAS', 'Number_of_Physicians_At_Arrival', 'Number_of_Physicians_At_3Hours_After', 'Number_of_Physicians_At_2Hours_After', 'Number_of_Physicians_At_1Hours_After', 'Number_of_Physicians_At_3Hours_Before', 'Number_of_Physicians_At_2Hours_Before', 'Number_of_Physicians_At_1Hours_Before', 'Labs_Ordered_Hour_Before_Arrival', 'Labs_Ordered_Hour_After_Arrival', 'DIs_Ordered_Hour_Before_Arrival', 'DIs_Ordered_Hour_After_Arrival', 'time_of_day_of_arrival_Midday', 'time_of_day_of_arrival_Morning Dusk', 'time_of_day_of_arrival_Night/Evening', 'time_of_day_of_arrival_Morning Dawn', 'PTN_AGE_1-10', 'PTN_AGE_11-20', 'PTN_AGE_21-30', 'PTN_AGE_31-40', 'PTN_AGE_41-50', 'PTN_AGE_51-60', 'PTN_AGE_61-70', 'PTN_AGE_71-80', 'PTN_AGE_81-90', 'PTN_AGE_91-100', 'PTN_AGE_>100', 'PTN_SEX_F', 'PTN_SEX_M']\n","    coefficient                                           word\n","0      0.000000                     ARRIVAL_MODE_Air Ambulance\n","1      0.000000           Number_of_Patients_In_Waiting_Before\n","2      0.000000      Number_of_Patients_In_Waiting_Before_CTAS\n","3      0.000089                                   PTN_AGE_1-10\n","4      0.000120               Labs_Ordered_Hour_Before_Arrival\n","5      0.000377                                   PTN_AGE_>100\n","6      0.000433                Labs_Ordered_Hour_After_Arrival\n","7      0.000684                         INIT_LOC_GRP_WR Non ED\n","8      0.001913                               INIT_LOC_GRP_MET\n","9      0.001977                            INIT_LOC_GRP_Intake\n","10     0.002257                 DIs_Ordered_Hour_After_Arrival\n","11     0.002401                      INIT_TREAT_LOC_GRP_Intake\n","12     0.002635                DIs_Ordered_Hour_Before_Arrival\n","13     0.002676            time_of_day_of_arrival_Morning Dawn\n","14     0.002723                              INIT_LOC_GRP_Main\n","15     0.004046                                 PTN_AGE_91-100\n","16     0.004300            time_of_day_of_arrival_Morning Dusk\n","17     0.005772                  time_of_day_of_arrival_Midday\n","18     0.006093           time_of_day_of_arrival_Night/Evening\n","19     0.006200                            INIT_LOC_GRP_WR MET\n","20     0.007475                      ARRIVAL_MODE_No Ambulance\n","21     0.007670                                  PTN_AGE_11-20\n","22     0.009096                        INIT_TREAT_LOC_GRP_Main\n","23     0.009958                         INIT_LOC_GRP_WR Intake\n","24     0.010122                                      PTN_SEX_F\n","25     0.010767                           INIT_LOC_GRP_WR Main\n","26     0.010963                                  PTN_AGE_81-90\n","27     0.011645                                  PTN_AGE_71-80\n","28     0.012136                                  PTN_AGE_61-70\n","29     0.012375                                  PTN_AGE_51-60\n","30     0.012707                                  PTN_AGE_41-50\n","31     0.012986                                      PTN_SEX_M\n","32     0.013617                                  PTN_AGE_31-40\n","33     0.013825                  ARRIVAL_MODE_Ground Ambulance\n","34     0.014724                                  PTN_AGE_21-30\n","35     0.018529                Number_of_Physicians_At_Arrival\n","36     0.020598          Number_of_Physicians_At_3Hours_Before\n","37     0.020727          Number_of_Physicians_At_1Hours_Before\n","38     0.021024          Number_of_Physicians_At_2Hours_Before\n","39     0.024403           Number_of_Physicians_At_2Hours_After\n","40     0.025071           Number_of_Physicians_At_1Hours_After\n","41     0.030160           Number_of_Physicians_At_3Hours_After\n","42     0.033458                         INIT_TREAT_LOC_GRP_MET\n","43     0.064415  Number_of_Patients_Waiting_For_Admission_CTAS\n","44     0.082542  Number_of_Patients_Waiting_For_Discharge_CTAS\n","45     0.098289       Number_of_Patients_In_Waiting_After_CTAS\n","46     0.100195       Number_of_Patients_Waiting_For_Admission\n","47     0.122669       Number_of_Patients_Waiting_For_Discharge\n","48     0.123156            Number_of_Patients_In_Waiting_After\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KtKVBLV_v38h"},"source":["### Artifical Neural Network"]},{"cell_type":"code","metadata":{"id":"bxeKU-6wdW25"},"source":["from keras.models import Sequential\n","from keras.layers import Activation, Dense\n","from tensorflow.keras import layers\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","from keras.optimizers import Adam\n","from sklearn.utils import class_weight\n","from sklearn.model_selection import cross_validate\n","import tensorflow as tf\n","from sklearn.metrics import confusion_matrix,f1_score, precision_score, recall_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9V6_qs8mapG0"},"source":["def buildModel(dim):\n","    model = Sequential()\n","    model.add(Dense(32, input_dim=dim, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(16, activation='relu'))\n","    model.add(Dense(8, activation='relu'))\n","    model.add(Dense(8, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdY7T-MzcBrY"},"source":["def fitModel(myData, model, Xtrain, yTrain, Xtest, yTest):\n","  opt = Adam(lr=0.0001)\n","  class_weight_dict = dict(enumerate(class_weight.compute_class_weight('balanced', np.unique(yTrain), yTrain)))\n","  model.compile(loss='mse', optimizer=opt, metrics=[\"accuracy\",tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n","  callbacks = [\n","            EarlyStopping(patience=100, verbose=1),\n","            ReduceLROnPlateau(factor=0.50, patience=25, min_lr=0.0001, verbose=1),\n","            ModelCheckpoint(\n","                filepath=\"Test1.h5\",\n","                verbose=1, save_best_only=True, save_weights_only=True, monitor=\"val_loss\", mode='min')]\n","  model.fit(Xtrain, yTrain, epochs=150, batch_size=50,validation_split=0.20,verbose=1,shuffle=True,callbacks=callbacks,class_weight=class_weight_dict)\n","  #y_pred = model.predict(Xtest)\n","  \"\"\" scoring = ['accuracy', 'precision', 'recall', 'roc_auc']\n","  scores = cross_validate(model, Xtrain,yTrain, cv =5, scoring=scoring, return_train_score=False)\n","  print(sum(scores[\"test_accuracy\"])/len(scores[\"test_accuracy\"]))\n","  print(sum(scores[\"test_precision\"])/len(scores[\"test_precision\"]))\n","  print(sum(scores[\"test_recall\"])/len(scores[\"test_recall\"]))\"\"\"\n","  y_pred = model.predict_classes(Xtest, verbose=0)\n","  print(\"Accuracy:\", accuracy_score(yTest, y_pred))\n","  print(\"Recall:\", precision_score(yTest, y_pred))\n","  print(\"Specificity:\", recall_score(yTest, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"byI95MF4wxfu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617559646729,"user_tz":360,"elapsed":203418,"user":{"displayName":"Sim Bhattarai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpaBPF0DuLN5KkInccG6Ttqk5D8haa72YxXR_6=s64","userId":"11084487050159240062"}},"outputId":"f8b2531a-b110-47d3-989b-dcb130088494"},"source":["model = buildModel(49)\n","fitModel(myData, model, Xtrain, yTrain, Xtest, yTest)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","598/598 [==============================] - 3s 3ms/step - loss: 0.2495 - accuracy: 0.4078 - precision_5: 0.4069 - recall_5: 0.9979 - val_loss: 0.2506 - val_accuracy: 0.4629 - val_precision_5: 0.4359 - val_recall_5: 0.9377\n","\n","Epoch 00001: val_loss improved from inf to 0.25065, saving model to Test1.h5\n","Epoch 2/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2465 - accuracy: 0.4726 - precision_5: 0.4329 - recall_5: 0.9019 - val_loss: 0.2472 - val_accuracy: 0.5689 - val_precision_5: 0.4923 - val_recall_5: 0.7606\n","\n","Epoch 00002: val_loss improved from 0.25065 to 0.24722, saving model to Test1.h5\n","Epoch 3/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2418 - accuracy: 0.5694 - precision_5: 0.4840 - recall_5: 0.7592 - val_loss: 0.2423 - val_accuracy: 0.6014 - val_precision_5: 0.5199 - val_recall_5: 0.6977\n","\n","Epoch 00003: val_loss improved from 0.24722 to 0.24229, saving model to Test1.h5\n","Epoch 4/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.6017 - precision_5: 0.5125 - recall_5: 0.7139 - val_loss: 0.2353 - val_accuracy: 0.6460 - val_precision_5: 0.5818 - val_recall_5: 0.5664\n","\n","Epoch 00004: val_loss improved from 0.24229 to 0.23534, saving model to Test1.h5\n","Epoch 5/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2314 - accuracy: 0.6318 - precision_5: 0.5465 - recall_5: 0.6551 - val_loss: 0.2349 - val_accuracy: 0.6292 - val_precision_5: 0.5477 - val_recall_5: 0.6866\n","\n","Epoch 00005: val_loss improved from 0.23534 to 0.23487, saving model to Test1.h5\n","Epoch 6/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2279 - accuracy: 0.6395 - precision_5: 0.5505 - recall_5: 0.6453 - val_loss: 0.2293 - val_accuracy: 0.6436 - val_precision_5: 0.5665 - val_recall_5: 0.6535\n","\n","Epoch 00006: val_loss improved from 0.23487 to 0.22925, saving model to Test1.h5\n","Epoch 7/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2235 - accuracy: 0.6517 - precision_5: 0.5671 - recall_5: 0.6233 - val_loss: 0.2284 - val_accuracy: 0.6370 - val_precision_5: 0.5552 - val_recall_5: 0.6939\n","\n","Epoch 00007: val_loss improved from 0.22925 to 0.22842, saving model to Test1.h5\n","Epoch 8/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2211 - accuracy: 0.6551 - precision_5: 0.5728 - recall_5: 0.6176 - val_loss: 0.2218 - val_accuracy: 0.6527 - val_precision_5: 0.5770 - val_recall_5: 0.6564\n","\n","Epoch 00008: val_loss improved from 0.22842 to 0.22178, saving model to Test1.h5\n","Epoch 9/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2189 - accuracy: 0.6595 - precision_5: 0.5823 - recall_5: 0.6144 - val_loss: 0.2170 - val_accuracy: 0.6622 - val_precision_5: 0.5941 - val_recall_5: 0.6243\n","\n","Epoch 00009: val_loss improved from 0.22178 to 0.21704, saving model to Test1.h5\n","Epoch 10/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2145 - accuracy: 0.6664 - precision_5: 0.5843 - recall_5: 0.6097 - val_loss: 0.2134 - val_accuracy: 0.6624 - val_precision_5: 0.6025 - val_recall_5: 0.5830\n","\n","Epoch 00010: val_loss improved from 0.21704 to 0.21339, saving model to Test1.h5\n","Epoch 11/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2157 - accuracy: 0.6620 - precision_5: 0.5835 - recall_5: 0.6214 - val_loss: 0.2121 - val_accuracy: 0.6650 - val_precision_5: 0.6039 - val_recall_5: 0.5938\n","\n","Epoch 00011: val_loss improved from 0.21339 to 0.21206, saving model to Test1.h5\n","Epoch 12/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2136 - accuracy: 0.6672 - precision_5: 0.5874 - recall_5: 0.6212 - val_loss: 0.2117 - val_accuracy: 0.6693 - val_precision_5: 0.6039 - val_recall_5: 0.6233\n","\n","Epoch 00012: val_loss improved from 0.21206 to 0.21166, saving model to Test1.h5\n","Epoch 13/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.6787 - precision_5: 0.6024 - recall_5: 0.6296 - val_loss: 0.2144 - val_accuracy: 0.6618 - val_precision_5: 0.5855 - val_recall_5: 0.6736\n","\n","Epoch 00013: val_loss did not improve from 0.21166\n","Epoch 14/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.6702 - precision_5: 0.5885 - recall_5: 0.6464 - val_loss: 0.2099 - val_accuracy: 0.6734 - val_precision_5: 0.6066 - val_recall_5: 0.6383\n","\n","Epoch 00014: val_loss improved from 0.21166 to 0.20993, saving model to Test1.h5\n","Epoch 15/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2109 - accuracy: 0.6728 - precision_5: 0.5938 - recall_5: 0.6301 - val_loss: 0.2097 - val_accuracy: 0.6733 - val_precision_5: 0.6037 - val_recall_5: 0.6523\n","\n","Epoch 00015: val_loss improved from 0.20993 to 0.20970, saving model to Test1.h5\n","Epoch 16/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2102 - accuracy: 0.6748 - precision_5: 0.6021 - recall_5: 0.6432 - val_loss: 0.2053 - val_accuracy: 0.6859 - val_precision_5: 0.6337 - val_recall_5: 0.6020\n","\n","Epoch 00016: val_loss improved from 0.20970 to 0.20527, saving model to Test1.h5\n","Epoch 17/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2074 - accuracy: 0.6794 - precision_5: 0.6069 - recall_5: 0.6352 - val_loss: 0.2050 - val_accuracy: 0.6876 - val_precision_5: 0.6322 - val_recall_5: 0.6170\n","\n","Epoch 00017: val_loss improved from 0.20527 to 0.20503, saving model to Test1.h5\n","Epoch 18/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2066 - accuracy: 0.6799 - precision_5: 0.6009 - recall_5: 0.6491 - val_loss: 0.2056 - val_accuracy: 0.6848 - val_precision_5: 0.6210 - val_recall_5: 0.6453\n","\n","Epoch 00018: val_loss did not improve from 0.20503\n","Epoch 19/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2061 - accuracy: 0.6843 - precision_5: 0.6099 - recall_5: 0.6578 - val_loss: 0.2036 - val_accuracy: 0.6885 - val_precision_5: 0.6288 - val_recall_5: 0.6354\n","\n","Epoch 00019: val_loss improved from 0.20503 to 0.20365, saving model to Test1.h5\n","Epoch 20/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2048 - accuracy: 0.6850 - precision_5: 0.6060 - recall_5: 0.6553 - val_loss: 0.2035 - val_accuracy: 0.6849 - val_precision_5: 0.6224 - val_recall_5: 0.6402\n","\n","Epoch 00020: val_loss improved from 0.20365 to 0.20345, saving model to Test1.h5\n","Epoch 21/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.6862 - precision_5: 0.6091 - recall_5: 0.6541 - val_loss: 0.2017 - val_accuracy: 0.6911 - val_precision_5: 0.6340 - val_recall_5: 0.6300\n","\n","Epoch 00021: val_loss improved from 0.20345 to 0.20173, saving model to Test1.h5\n","Epoch 22/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2017 - accuracy: 0.6898 - precision_5: 0.6124 - recall_5: 0.6600 - val_loss: 0.2017 - val_accuracy: 0.6940 - val_precision_5: 0.6335 - val_recall_5: 0.6484\n","\n","Epoch 00022: val_loss improved from 0.20173 to 0.20169, saving model to Test1.h5\n","Epoch 23/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2022 - accuracy: 0.6915 - precision_5: 0.6166 - recall_5: 0.6615 - val_loss: 0.2035 - val_accuracy: 0.6871 - val_precision_5: 0.6149 - val_recall_5: 0.6872\n","\n","Epoch 00023: val_loss did not improve from 0.20169\n","Epoch 24/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2007 - accuracy: 0.6917 - precision_5: 0.6143 - recall_5: 0.6741 - val_loss: 0.2000 - val_accuracy: 0.6955 - val_precision_5: 0.6360 - val_recall_5: 0.6475\n","\n","Epoch 00024: val_loss improved from 0.20169 to 0.19996, saving model to Test1.h5\n","Epoch 25/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.6943 - precision_5: 0.6180 - recall_5: 0.6713 - val_loss: 0.1982 - val_accuracy: 0.6979 - val_precision_5: 0.6475 - val_recall_5: 0.6202\n","\n","Epoch 00025: val_loss improved from 0.19996 to 0.19820, saving model to Test1.h5\n","Epoch 26/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1994 - accuracy: 0.6993 - precision_5: 0.6217 - recall_5: 0.6774 - val_loss: 0.2005 - val_accuracy: 0.6933 - val_precision_5: 0.6262 - val_recall_5: 0.6742\n","\n","Epoch 00026: val_loss did not improve from 0.19820\n","Epoch 27/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2002 - accuracy: 0.6957 - precision_5: 0.6184 - recall_5: 0.6749 - val_loss: 0.1986 - val_accuracy: 0.6972 - val_precision_5: 0.6368 - val_recall_5: 0.6538\n","\n","Epoch 00027: val_loss did not improve from 0.19820\n","Epoch 28/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1989 - accuracy: 0.6966 - precision_5: 0.6206 - recall_5: 0.6881 - val_loss: 0.1985 - val_accuracy: 0.6964 - val_precision_5: 0.6325 - val_recall_5: 0.6659\n","\n","Epoch 00028: val_loss did not improve from 0.19820\n","Epoch 29/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1966 - accuracy: 0.7016 - precision_5: 0.6227 - recall_5: 0.6789 - val_loss: 0.1962 - val_accuracy: 0.7026 - val_precision_5: 0.6498 - val_recall_5: 0.6370\n","\n","Epoch 00029: val_loss improved from 0.19820 to 0.19616, saving model to Test1.h5\n","Epoch 30/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.6998 - precision_5: 0.6205 - recall_5: 0.6761 - val_loss: 0.1987 - val_accuracy: 0.6972 - val_precision_5: 0.6287 - val_recall_5: 0.6863\n","\n","Epoch 00030: val_loss did not improve from 0.19616\n","Epoch 31/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.7028 - precision_5: 0.6279 - recall_5: 0.6936 - val_loss: 0.1965 - val_accuracy: 0.7023 - val_precision_5: 0.6409 - val_recall_5: 0.6666\n","\n","Epoch 00031: val_loss did not improve from 0.19616\n","Epoch 32/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.7055 - precision_5: 0.6277 - recall_5: 0.6831 - val_loss: 0.1968 - val_accuracy: 0.7008 - val_precision_5: 0.6358 - val_recall_5: 0.6780\n","\n","Epoch 00032: val_loss did not improve from 0.19616\n","Epoch 33/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.7031 - precision_5: 0.6247 - recall_5: 0.6855 - val_loss: 0.1962 - val_accuracy: 0.7039 - val_precision_5: 0.6398 - val_recall_5: 0.6793\n","\n","Epoch 00033: val_loss did not improve from 0.19616\n","Epoch 34/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.7081 - precision_5: 0.6280 - recall_5: 0.6913 - val_loss: 0.1974 - val_accuracy: 0.6987 - val_precision_5: 0.6272 - val_recall_5: 0.7012\n","\n","Epoch 00034: val_loss did not improve from 0.19616\n","Epoch 35/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.7065 - precision_5: 0.6284 - recall_5: 0.6938 - val_loss: 0.1985 - val_accuracy: 0.6971 - val_precision_5: 0.6222 - val_recall_5: 0.7146\n","\n","Epoch 00035: val_loss did not improve from 0.19616\n","Epoch 36/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.7047 - precision_5: 0.6269 - recall_5: 0.6964 - val_loss: 0.1939 - val_accuracy: 0.7077 - val_precision_5: 0.6526 - val_recall_5: 0.6538\n","\n","Epoch 00036: val_loss improved from 0.19616 to 0.19393, saving model to Test1.h5\n","Epoch 37/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1935 - accuracy: 0.7052 - precision_5: 0.6259 - recall_5: 0.6872 - val_loss: 0.1934 - val_accuracy: 0.7075 - val_precision_5: 0.6525 - val_recall_5: 0.6535\n","\n","Epoch 00037: val_loss improved from 0.19393 to 0.19341, saving model to Test1.h5\n","Epoch 38/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.7045 - precision_5: 0.6274 - recall_5: 0.6890 - val_loss: 0.1960 - val_accuracy: 0.7012 - val_precision_5: 0.6325 - val_recall_5: 0.6936\n","\n","Epoch 00038: val_loss did not improve from 0.19341\n","Epoch 39/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.7026 - precision_5: 0.6243 - recall_5: 0.6926 - val_loss: 0.1949 - val_accuracy: 0.7016 - val_precision_5: 0.6338 - val_recall_5: 0.6904\n","\n","Epoch 00039: val_loss did not improve from 0.19341\n","Epoch 40/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1925 - accuracy: 0.7085 - precision_5: 0.6330 - recall_5: 0.6962 - val_loss: 0.1961 - val_accuracy: 0.7033 - val_precision_5: 0.6311 - val_recall_5: 0.7107\n","\n","Epoch 00040: val_loss did not improve from 0.19341\n","Epoch 41/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1934 - accuracy: 0.7062 - precision_5: 0.6295 - recall_5: 0.6950 - val_loss: 0.1953 - val_accuracy: 0.7030 - val_precision_5: 0.6328 - val_recall_5: 0.7022\n","\n","Epoch 00041: val_loss did not improve from 0.19341\n","Epoch 42/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.7105 - precision_5: 0.6289 - recall_5: 0.6996 - val_loss: 0.1939 - val_accuracy: 0.7070 - val_precision_5: 0.6407 - val_recall_5: 0.6926\n","\n","Epoch 00042: val_loss did not improve from 0.19341\n","Epoch 43/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1914 - accuracy: 0.7100 - precision_5: 0.6321 - recall_5: 0.6938 - val_loss: 0.1915 - val_accuracy: 0.7103 - val_precision_5: 0.6587 - val_recall_5: 0.6478\n","\n","Epoch 00043: val_loss improved from 0.19341 to 0.19151, saving model to Test1.h5\n","Epoch 44/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1902 - accuracy: 0.7129 - precision_5: 0.6395 - recall_5: 0.7054 - val_loss: 0.1938 - val_accuracy: 0.7059 - val_precision_5: 0.6381 - val_recall_5: 0.6968\n","\n","Epoch 00044: val_loss did not improve from 0.19151\n","Epoch 45/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1898 - accuracy: 0.7111 - precision_5: 0.6291 - recall_5: 0.6972 - val_loss: 0.1934 - val_accuracy: 0.7058 - val_precision_5: 0.6393 - val_recall_5: 0.6914\n","\n","Epoch 00045: val_loss did not improve from 0.19151\n","Epoch 46/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.7096 - precision_5: 0.6343 - recall_5: 0.7050 - val_loss: 0.1925 - val_accuracy: 0.7075 - val_precision_5: 0.6442 - val_recall_5: 0.6825\n","\n","Epoch 00046: val_loss did not improve from 0.19151\n","Epoch 47/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1901 - accuracy: 0.7109 - precision_5: 0.6331 - recall_5: 0.7057 - val_loss: 0.1921 - val_accuracy: 0.7094 - val_precision_5: 0.6485 - val_recall_5: 0.6767\n","\n","Epoch 00047: val_loss did not improve from 0.19151\n","Epoch 48/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.7118 - precision_5: 0.6368 - recall_5: 0.7042 - val_loss: 0.1967 - val_accuracy: 0.6964 - val_precision_5: 0.6177 - val_recall_5: 0.7324\n","\n","Epoch 00048: val_loss did not improve from 0.19151\n","Epoch 49/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.7220 - precision_5: 0.6422 - recall_5: 0.7229 - val_loss: 0.1911 - val_accuracy: 0.7111 - val_precision_5: 0.6556 - val_recall_5: 0.6615\n","\n","Epoch 00049: val_loss improved from 0.19151 to 0.19112, saving model to Test1.h5\n","Epoch 50/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.7128 - precision_5: 0.6347 - recall_5: 0.7066 - val_loss: 0.1942 - val_accuracy: 0.7038 - val_precision_5: 0.6334 - val_recall_5: 0.7041\n","\n","Epoch 00050: val_loss did not improve from 0.19112\n","Epoch 51/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1879 - accuracy: 0.7164 - precision_5: 0.6410 - recall_5: 0.7115 - val_loss: 0.1899 - val_accuracy: 0.7117 - val_precision_5: 0.6635 - val_recall_5: 0.6399\n","\n","Epoch 00051: val_loss improved from 0.19112 to 0.18988, saving model to Test1.h5\n","Epoch 52/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1902 - accuracy: 0.7119 - precision_5: 0.6397 - recall_5: 0.7020 - val_loss: 0.1917 - val_accuracy: 0.7094 - val_precision_5: 0.6481 - val_recall_5: 0.6780\n","\n","Epoch 00052: val_loss did not improve from 0.18988\n","Epoch 53/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.7146 - precision_5: 0.6391 - recall_5: 0.7020 - val_loss: 0.1945 - val_accuracy: 0.7033 - val_precision_5: 0.6305 - val_recall_5: 0.7133\n","\n","Epoch 00053: val_loss did not improve from 0.18988\n","Epoch 54/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1885 - accuracy: 0.7173 - precision_5: 0.6366 - recall_5: 0.7065 - val_loss: 0.1905 - val_accuracy: 0.7110 - val_precision_5: 0.6546 - val_recall_5: 0.6643\n","\n","Epoch 00054: val_loss did not improve from 0.18988\n","Epoch 55/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.7180 - precision_5: 0.6405 - recall_5: 0.7119 - val_loss: 0.1904 - val_accuracy: 0.7118 - val_precision_5: 0.6536 - val_recall_5: 0.6716\n","\n","Epoch 00055: val_loss did not improve from 0.18988\n","Epoch 56/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1857 - accuracy: 0.7202 - precision_5: 0.6442 - recall_5: 0.7139 - val_loss: 0.1927 - val_accuracy: 0.7067 - val_precision_5: 0.6370 - val_recall_5: 0.7057\n","\n","Epoch 00056: val_loss did not improve from 0.18988\n","Epoch 57/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.7194 - precision_5: 0.6403 - recall_5: 0.7138 - val_loss: 0.1907 - val_accuracy: 0.7110 - val_precision_5: 0.6497 - val_recall_5: 0.6809\n","\n","Epoch 00057: val_loss did not improve from 0.18988\n","Epoch 58/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.7145 - precision_5: 0.6350 - recall_5: 0.7033 - val_loss: 0.1906 - val_accuracy: 0.7120 - val_precision_5: 0.6489 - val_recall_5: 0.6885\n","\n","Epoch 00058: val_loss did not improve from 0.18988\n","Epoch 59/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1861 - accuracy: 0.7211 - precision_5: 0.6440 - recall_5: 0.7208 - val_loss: 0.1900 - val_accuracy: 0.7095 - val_precision_5: 0.6513 - val_recall_5: 0.6678\n","\n","Epoch 00059: val_loss did not improve from 0.18988\n","Epoch 60/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1886 - accuracy: 0.7158 - precision_5: 0.6388 - recall_5: 0.7044 - val_loss: 0.1919 - val_accuracy: 0.7081 - val_precision_5: 0.6391 - val_recall_5: 0.7047\n","\n","Epoch 00060: val_loss did not improve from 0.18988\n","Epoch 61/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.7203 - precision_5: 0.6438 - recall_5: 0.7164 - val_loss: 0.1922 - val_accuracy: 0.7085 - val_precision_5: 0.6371 - val_recall_5: 0.7149\n","\n","Epoch 00061: val_loss did not improve from 0.18988\n","Epoch 62/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1867 - accuracy: 0.7132 - precision_5: 0.6347 - recall_5: 0.7038 - val_loss: 0.1888 - val_accuracy: 0.7128 - val_precision_5: 0.6614 - val_recall_5: 0.6513\n","\n","Epoch 00062: val_loss improved from 0.18988 to 0.18884, saving model to Test1.h5\n","Epoch 63/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1874 - accuracy: 0.7171 - precision_5: 0.6413 - recall_5: 0.7152 - val_loss: 0.1914 - val_accuracy: 0.7089 - val_precision_5: 0.6400 - val_recall_5: 0.7053\n","\n","Epoch 00063: val_loss did not improve from 0.18884\n","Epoch 64/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1841 - accuracy: 0.7250 - precision_5: 0.6460 - recall_5: 0.7177 - val_loss: 0.1926 - val_accuracy: 0.7085 - val_precision_5: 0.6355 - val_recall_5: 0.7216\n","\n","Epoch 00064: val_loss did not improve from 0.18884\n","Epoch 65/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1846 - accuracy: 0.7235 - precision_5: 0.6447 - recall_5: 0.7229 - val_loss: 0.1918 - val_accuracy: 0.7094 - val_precision_5: 0.6378 - val_recall_5: 0.7171\n","\n","Epoch 00065: val_loss did not improve from 0.18884\n","Epoch 66/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1852 - accuracy: 0.7254 - precision_5: 0.6491 - recall_5: 0.7273 - val_loss: 0.1930 - val_accuracy: 0.7037 - val_precision_5: 0.6283 - val_recall_5: 0.7254\n","\n","Epoch 00066: val_loss did not improve from 0.18884\n","Epoch 67/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1846 - accuracy: 0.7220 - precision_5: 0.6413 - recall_5: 0.7170 - val_loss: 0.1924 - val_accuracy: 0.7050 - val_precision_5: 0.6316 - val_recall_5: 0.7187\n","\n","Epoch 00067: val_loss did not improve from 0.18884\n","Epoch 68/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1853 - accuracy: 0.7202 - precision_5: 0.6415 - recall_5: 0.7187 - val_loss: 0.1933 - val_accuracy: 0.7037 - val_precision_5: 0.6273 - val_recall_5: 0.7298\n","\n","Epoch 00068: val_loss did not improve from 0.18884\n","Epoch 69/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.7241 - precision_5: 0.6446 - recall_5: 0.7287 - val_loss: 0.1888 - val_accuracy: 0.7134 - val_precision_5: 0.6574 - val_recall_5: 0.6672\n","\n","Epoch 00069: val_loss improved from 0.18884 to 0.18877, saving model to Test1.h5\n","Epoch 70/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.7219 - precision_5: 0.6444 - recall_5: 0.7122 - val_loss: 0.1908 - val_accuracy: 0.7097 - val_precision_5: 0.6406 - val_recall_5: 0.7076\n","\n","Epoch 00070: val_loss did not improve from 0.18877\n","Epoch 71/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1861 - accuracy: 0.7169 - precision_5: 0.6384 - recall_5: 0.7160 - val_loss: 0.1924 - val_accuracy: 0.7055 - val_precision_5: 0.6307 - val_recall_5: 0.7257\n","\n","Epoch 00071: val_loss did not improve from 0.18877\n","Epoch 72/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.7194 - precision_5: 0.6434 - recall_5: 0.7236 - val_loss: 0.1923 - val_accuracy: 0.7034 - val_precision_5: 0.6307 - val_recall_5: 0.7133\n","\n","Epoch 00072: val_loss did not improve from 0.18877\n","Epoch 73/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1836 - accuracy: 0.7225 - precision_5: 0.6461 - recall_5: 0.7158 - val_loss: 0.1890 - val_accuracy: 0.7124 - val_precision_5: 0.6508 - val_recall_5: 0.6837\n","\n","Epoch 00073: val_loss did not improve from 0.18877\n","Epoch 74/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1855 - accuracy: 0.7221 - precision_5: 0.6493 - recall_5: 0.7191 - val_loss: 0.1878 - val_accuracy: 0.7136 - val_precision_5: 0.6610 - val_recall_5: 0.6564\n","\n","Epoch 00074: val_loss improved from 0.18877 to 0.18783, saving model to Test1.h5\n","Epoch 75/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.7280 - precision_5: 0.6535 - recall_5: 0.7269 - val_loss: 0.1884 - val_accuracy: 0.7133 - val_precision_5: 0.6543 - val_recall_5: 0.6767\n","\n","Epoch 00075: val_loss did not improve from 0.18783\n","Epoch 76/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.7203 - precision_5: 0.6427 - recall_5: 0.7171 - val_loss: 0.1887 - val_accuracy: 0.7105 - val_precision_5: 0.6491 - val_recall_5: 0.6802\n","\n","Epoch 00076: val_loss did not improve from 0.18783\n","Epoch 77/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.7274 - precision_5: 0.6526 - recall_5: 0.7222 - val_loss: 0.1883 - val_accuracy: 0.7105 - val_precision_5: 0.6534 - val_recall_5: 0.6656\n","\n","Epoch 00077: val_loss did not improve from 0.18783\n","Epoch 78/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1842 - accuracy: 0.7215 - precision_5: 0.6454 - recall_5: 0.7178 - val_loss: 0.1877 - val_accuracy: 0.7133 - val_precision_5: 0.6560 - val_recall_5: 0.6710\n","\n","Epoch 00078: val_loss improved from 0.18783 to 0.18772, saving model to Test1.h5\n","Epoch 79/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.7257 - precision_5: 0.6471 - recall_5: 0.7160 - val_loss: 0.1891 - val_accuracy: 0.7129 - val_precision_5: 0.6479 - val_recall_5: 0.6968\n","\n","Epoch 00079: val_loss did not improve from 0.18772\n","Epoch 80/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.7201 - precision_5: 0.6426 - recall_5: 0.7175 - val_loss: 0.1889 - val_accuracy: 0.7094 - val_precision_5: 0.6451 - val_recall_5: 0.6888\n","\n","Epoch 00080: val_loss did not improve from 0.18772\n","Epoch 81/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.7201 - precision_5: 0.6443 - recall_5: 0.7263 - val_loss: 0.1900 - val_accuracy: 0.7094 - val_precision_5: 0.6397 - val_recall_5: 0.7095\n","\n","Epoch 00081: val_loss did not improve from 0.18772\n","Epoch 82/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1839 - accuracy: 0.7208 - precision_5: 0.6436 - recall_5: 0.7271 - val_loss: 0.1905 - val_accuracy: 0.7071 - val_precision_5: 0.6349 - val_recall_5: 0.7165\n","\n","Epoch 00082: val_loss did not improve from 0.18772\n","Epoch 83/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.7214 - precision_5: 0.6451 - recall_5: 0.7165 - val_loss: 0.1916 - val_accuracy: 0.7071 - val_precision_5: 0.6330 - val_recall_5: 0.7247\n","\n","Epoch 00083: val_loss did not improve from 0.18772\n","Epoch 84/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.7224 - precision_5: 0.6448 - recall_5: 0.7267 - val_loss: 0.1898 - val_accuracy: 0.7110 - val_precision_5: 0.6421 - val_recall_5: 0.7088\n","\n","Epoch 00084: val_loss did not improve from 0.18772\n","Epoch 85/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.7250 - precision_5: 0.6488 - recall_5: 0.7250 - val_loss: 0.1906 - val_accuracy: 0.7077 - val_precision_5: 0.6344 - val_recall_5: 0.7216\n","\n","Epoch 00085: val_loss did not improve from 0.18772\n","Epoch 86/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.7213 - precision_5: 0.6388 - recall_5: 0.7137 - val_loss: 0.1873 - val_accuracy: 0.7150 - val_precision_5: 0.6615 - val_recall_5: 0.6621\n","\n","Epoch 00086: val_loss improved from 0.18772 to 0.18725, saving model to Test1.h5\n","Epoch 87/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.7266 - precision_5: 0.6501 - recall_5: 0.7180 - val_loss: 0.1899 - val_accuracy: 0.7081 - val_precision_5: 0.6391 - val_recall_5: 0.7047\n","\n","Epoch 00087: val_loss did not improve from 0.18725\n","Epoch 88/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1839 - accuracy: 0.7224 - precision_5: 0.6425 - recall_5: 0.7122 - val_loss: 0.1923 - val_accuracy: 0.7054 - val_precision_5: 0.6282 - val_recall_5: 0.7359\n","\n","Epoch 00088: val_loss did not improve from 0.18725\n","Epoch 89/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7315 - precision_5: 0.6564 - recall_5: 0.7319 - val_loss: 0.1918 - val_accuracy: 0.7047 - val_precision_5: 0.6295 - val_recall_5: 0.7260\n","\n","Epoch 00089: val_loss did not improve from 0.18725\n","Epoch 90/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.7242 - precision_5: 0.6498 - recall_5: 0.7264 - val_loss: 0.1882 - val_accuracy: 0.7101 - val_precision_5: 0.6518 - val_recall_5: 0.6688\n","\n","Epoch 00090: val_loss did not improve from 0.18725\n","Epoch 91/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.7259 - precision_5: 0.6522 - recall_5: 0.7230 - val_loss: 0.1870 - val_accuracy: 0.7132 - val_precision_5: 0.6600 - val_recall_5: 0.6577\n","\n","Epoch 00091: val_loss improved from 0.18725 to 0.18698, saving model to Test1.h5\n","Epoch 92/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.7255 - precision_5: 0.6515 - recall_5: 0.7250 - val_loss: 0.1868 - val_accuracy: 0.7140 - val_precision_5: 0.6626 - val_recall_5: 0.6535\n","\n","Epoch 00092: val_loss improved from 0.18698 to 0.18678, saving model to Test1.h5\n","Epoch 93/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.7260 - precision_5: 0.6506 - recall_5: 0.7219 - val_loss: 0.1877 - val_accuracy: 0.7113 - val_precision_5: 0.6513 - val_recall_5: 0.6767\n","\n","Epoch 00093: val_loss did not improve from 0.18678\n","Epoch 94/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1831 - accuracy: 0.7232 - precision_5: 0.6462 - recall_5: 0.7220 - val_loss: 0.1912 - val_accuracy: 0.7074 - val_precision_5: 0.6336 - val_recall_5: 0.7235\n","\n","Epoch 00094: val_loss did not improve from 0.18678\n","Epoch 95/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.7303 - precision_5: 0.6509 - recall_5: 0.7300 - val_loss: 0.1917 - val_accuracy: 0.7033 - val_precision_5: 0.6263 - val_recall_5: 0.7320\n","\n","Epoch 00095: val_loss did not improve from 0.18678\n","Epoch 96/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.7259 - precision_5: 0.6494 - recall_5: 0.7251 - val_loss: 0.1878 - val_accuracy: 0.7126 - val_precision_5: 0.6520 - val_recall_5: 0.6812\n","\n","Epoch 00096: val_loss did not improve from 0.18678\n","Epoch 97/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.7320 - precision_5: 0.6560 - recall_5: 0.7280 - val_loss: 0.1886 - val_accuracy: 0.7097 - val_precision_5: 0.6459 - val_recall_5: 0.6875\n","\n","Epoch 00097: val_loss did not improve from 0.18678\n","Epoch 98/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.7235 - precision_5: 0.6454 - recall_5: 0.7204 - val_loss: 0.1933 - val_accuracy: 0.7010 - val_precision_5: 0.6220 - val_recall_5: 0.7390\n","\n","Epoch 00098: val_loss did not improve from 0.18678\n","Epoch 99/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.7235 - precision_5: 0.6435 - recall_5: 0.7278 - val_loss: 0.1886 - val_accuracy: 0.7124 - val_precision_5: 0.6453 - val_recall_5: 0.7038\n","\n","Epoch 00099: val_loss did not improve from 0.18678\n","Epoch 100/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1807 - accuracy: 0.7274 - precision_5: 0.6490 - recall_5: 0.7257 - val_loss: 0.1908 - val_accuracy: 0.7095 - val_precision_5: 0.6359 - val_recall_5: 0.7257\n","\n","Epoch 00100: val_loss did not improve from 0.18678\n","Epoch 101/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.7235 - precision_5: 0.6459 - recall_5: 0.7260 - val_loss: 0.1900 - val_accuracy: 0.7071 - val_precision_5: 0.6339 - val_recall_5: 0.7209\n","\n","Epoch 00101: val_loss did not improve from 0.18678\n","Epoch 102/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.7270 - precision_5: 0.6482 - recall_5: 0.7315 - val_loss: 0.1895 - val_accuracy: 0.7065 - val_precision_5: 0.6353 - val_recall_5: 0.7114\n","\n","Epoch 00102: val_loss did not improve from 0.18678\n","Epoch 103/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7275 - precision_5: 0.6503 - recall_5: 0.7203 - val_loss: 0.1895 - val_accuracy: 0.7089 - val_precision_5: 0.6388 - val_recall_5: 0.7101\n","\n","Epoch 00103: val_loss did not improve from 0.18678\n","Epoch 104/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1797 - accuracy: 0.7300 - precision_5: 0.6514 - recall_5: 0.7258 - val_loss: 0.1872 - val_accuracy: 0.7116 - val_precision_5: 0.6543 - val_recall_5: 0.6678\n","\n","Epoch 00104: val_loss did not improve from 0.18678\n","Epoch 105/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.7264 - precision_5: 0.6522 - recall_5: 0.7228 - val_loss: 0.1922 - val_accuracy: 0.7043 - val_precision_5: 0.6270 - val_recall_5: 0.7352\n","\n","Epoch 00105: val_loss did not improve from 0.18678\n","Epoch 106/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7258 - precision_5: 0.6494 - recall_5: 0.7237 - val_loss: 0.1900 - val_accuracy: 0.7093 - val_precision_5: 0.6375 - val_recall_5: 0.7177\n","\n","Epoch 00106: val_loss did not improve from 0.18678\n","Epoch 107/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1810 - accuracy: 0.7263 - precision_5: 0.6465 - recall_5: 0.7194 - val_loss: 0.1897 - val_accuracy: 0.7063 - val_precision_5: 0.6358 - val_recall_5: 0.7082\n","\n","Epoch 00107: val_loss did not improve from 0.18678\n","Epoch 108/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1807 - accuracy: 0.7296 - precision_5: 0.6524 - recall_5: 0.7284 - val_loss: 0.1923 - val_accuracy: 0.7012 - val_precision_5: 0.6225 - val_recall_5: 0.7384\n","\n","Epoch 00108: val_loss did not improve from 0.18678\n","Epoch 109/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.7276 - precision_5: 0.6495 - recall_5: 0.7281 - val_loss: 0.1868 - val_accuracy: 0.7133 - val_precision_5: 0.6620 - val_recall_5: 0.6519\n","\n","Epoch 00109: val_loss did not improve from 0.18678\n","Epoch 110/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.7277 - precision_5: 0.6516 - recall_5: 0.7293 - val_loss: 0.1930 - val_accuracy: 0.7022 - val_precision_5: 0.6230 - val_recall_5: 0.7413\n","\n","Epoch 00110: val_loss did not improve from 0.18678\n","Epoch 111/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.7268 - precision_5: 0.6479 - recall_5: 0.7270 - val_loss: 0.1861 - val_accuracy: 0.7160 - val_precision_5: 0.6640 - val_recall_5: 0.6589\n","\n","Epoch 00111: val_loss improved from 0.18678 to 0.18613, saving model to Test1.h5\n","Epoch 112/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.7258 - precision_5: 0.6505 - recall_5: 0.7191 - val_loss: 0.1936 - val_accuracy: 0.7014 - val_precision_5: 0.6203 - val_recall_5: 0.7498\n","\n","Epoch 00112: val_loss did not improve from 0.18613\n","Epoch 113/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.7262 - precision_5: 0.6445 - recall_5: 0.7286 - val_loss: 0.1909 - val_accuracy: 0.7045 - val_precision_5: 0.6290 - val_recall_5: 0.7270\n","\n","Epoch 00113: val_loss did not improve from 0.18613\n","Epoch 114/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.7275 - precision_5: 0.6494 - recall_5: 0.7282 - val_loss: 0.1888 - val_accuracy: 0.7106 - val_precision_5: 0.6437 - val_recall_5: 0.7006\n","\n","Epoch 00114: val_loss did not improve from 0.18613\n","Epoch 115/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7325 - precision_5: 0.6552 - recall_5: 0.7324 - val_loss: 0.1885 - val_accuracy: 0.7117 - val_precision_5: 0.6445 - val_recall_5: 0.7031\n","\n","Epoch 00115: val_loss did not improve from 0.18613\n","Epoch 116/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1805 - accuracy: 0.7283 - precision_5: 0.6512 - recall_5: 0.7244 - val_loss: 0.1882 - val_accuracy: 0.7111 - val_precision_5: 0.6472 - val_recall_5: 0.6904\n","\n","Epoch 00116: val_loss did not improve from 0.18613\n","Epoch 117/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.7317 - precision_5: 0.6580 - recall_5: 0.7295 - val_loss: 0.1942 - val_accuracy: 0.7026 - val_precision_5: 0.6202 - val_recall_5: 0.7575\n","\n","Epoch 00117: val_loss did not improve from 0.18613\n","Epoch 118/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.7279 - precision_5: 0.6481 - recall_5: 0.7275 - val_loss: 0.1883 - val_accuracy: 0.7105 - val_precision_5: 0.6436 - val_recall_5: 0.7003\n","\n","Epoch 00118: val_loss did not improve from 0.18613\n","Epoch 119/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7333 - precision_5: 0.6549 - recall_5: 0.7288 - val_loss: 0.1914 - val_accuracy: 0.7051 - val_precision_5: 0.6292 - val_recall_5: 0.7298\n","\n","Epoch 00119: val_loss did not improve from 0.18613\n","Epoch 120/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1794 - accuracy: 0.7297 - precision_5: 0.6498 - recall_5: 0.7283 - val_loss: 0.1873 - val_accuracy: 0.7126 - val_precision_5: 0.6510 - val_recall_5: 0.6847\n","\n","Epoch 00120: val_loss did not improve from 0.18613\n","Epoch 121/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7288 - precision_5: 0.6545 - recall_5: 0.7281 - val_loss: 0.1911 - val_accuracy: 0.7067 - val_precision_5: 0.6322 - val_recall_5: 0.7260\n","\n","Epoch 00121: val_loss did not improve from 0.18613\n","Epoch 122/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.7286 - precision_5: 0.6511 - recall_5: 0.7289 - val_loss: 0.1918 - val_accuracy: 0.7046 - val_precision_5: 0.6285 - val_recall_5: 0.7301\n","\n","Epoch 00122: val_loss did not improve from 0.18613\n","Epoch 123/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.7306 - precision_5: 0.6542 - recall_5: 0.7301 - val_loss: 0.1919 - val_accuracy: 0.7042 - val_precision_5: 0.6259 - val_recall_5: 0.7394\n","\n","Epoch 00123: val_loss did not improve from 0.18613\n","Epoch 124/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.7326 - precision_5: 0.6564 - recall_5: 0.7323 - val_loss: 0.1914 - val_accuracy: 0.7039 - val_precision_5: 0.6277 - val_recall_5: 0.7295\n","\n","Epoch 00124: val_loss did not improve from 0.18613\n","Epoch 125/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7255 - precision_5: 0.6465 - recall_5: 0.7282 - val_loss: 0.1883 - val_accuracy: 0.7113 - val_precision_5: 0.6437 - val_recall_5: 0.7041\n","\n","Epoch 00125: val_loss did not improve from 0.18613\n","Epoch 126/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7350 - precision_5: 0.6573 - recall_5: 0.7272 - val_loss: 0.1897 - val_accuracy: 0.7093 - val_precision_5: 0.6361 - val_recall_5: 0.7235\n","\n","Epoch 00126: val_loss did not improve from 0.18613\n","Epoch 127/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1807 - accuracy: 0.7293 - precision_5: 0.6528 - recall_5: 0.7300 - val_loss: 0.1896 - val_accuracy: 0.7073 - val_precision_5: 0.6374 - val_recall_5: 0.7069\n","\n","Epoch 00127: val_loss did not improve from 0.18613\n","Epoch 128/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.7307 - precision_5: 0.6545 - recall_5: 0.7229 - val_loss: 0.1880 - val_accuracy: 0.7103 - val_precision_5: 0.6474 - val_recall_5: 0.6853\n","\n","Epoch 00128: val_loss did not improve from 0.18613\n","Epoch 129/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7341 - precision_5: 0.6578 - recall_5: 0.7251 - val_loss: 0.1905 - val_accuracy: 0.7086 - val_precision_5: 0.6354 - val_recall_5: 0.7225\n","\n","Epoch 00129: val_loss did not improve from 0.18613\n","Epoch 130/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.7278 - precision_5: 0.6497 - recall_5: 0.7270 - val_loss: 0.1889 - val_accuracy: 0.7089 - val_precision_5: 0.6395 - val_recall_5: 0.7076\n","\n","Epoch 00130: val_loss did not improve from 0.18613\n","Epoch 131/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.7295 - precision_5: 0.6533 - recall_5: 0.7301 - val_loss: 0.1906 - val_accuracy: 0.7078 - val_precision_5: 0.6333 - val_recall_5: 0.7273\n","\n","Epoch 00131: val_loss did not improve from 0.18613\n","Epoch 132/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.7304 - precision_5: 0.6554 - recall_5: 0.7316 - val_loss: 0.1881 - val_accuracy: 0.7118 - val_precision_5: 0.6458 - val_recall_5: 0.6990\n","\n","Epoch 00132: val_loss did not improve from 0.18613\n","Epoch 133/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7337 - precision_5: 0.6610 - recall_5: 0.7312 - val_loss: 0.1940 - val_accuracy: 0.7015 - val_precision_5: 0.6200 - val_recall_5: 0.7521\n","\n","Epoch 00133: val_loss did not improve from 0.18613\n","Epoch 134/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7314 - precision_5: 0.6528 - recall_5: 0.7330 - val_loss: 0.1870 - val_accuracy: 0.7138 - val_precision_5: 0.6546 - val_recall_5: 0.6783\n","\n","Epoch 00134: val_loss did not improve from 0.18613\n","Epoch 135/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.7312 - precision_5: 0.6573 - recall_5: 0.7273 - val_loss: 0.1873 - val_accuracy: 0.7142 - val_precision_5: 0.6543 - val_recall_5: 0.6815\n","\n","Epoch 00135: val_loss did not improve from 0.18613\n","Epoch 136/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7367 - precision_5: 0.6600 - recall_5: 0.7290 - val_loss: 0.1875 - val_accuracy: 0.7114 - val_precision_5: 0.6476 - val_recall_5: 0.6904\n","\n","Epoch 00136: val_loss did not improve from 0.18613\n","Epoch 137/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7371 - precision_5: 0.6637 - recall_5: 0.7313 - val_loss: 0.1864 - val_accuracy: 0.7158 - val_precision_5: 0.6648 - val_recall_5: 0.6558\n","\n","Epoch 00137: val_loss did not improve from 0.18613\n","Epoch 138/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7354 - precision_5: 0.6603 - recall_5: 0.7286 - val_loss: 0.1904 - val_accuracy: 0.7063 - val_precision_5: 0.6318 - val_recall_5: 0.7254\n","\n","Epoch 00138: val_loss did not improve from 0.18613\n","Epoch 139/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.7335 - precision_5: 0.6567 - recall_5: 0.7365 - val_loss: 0.1906 - val_accuracy: 0.7071 - val_precision_5: 0.6331 - val_recall_5: 0.7244\n","\n","Epoch 00139: val_loss did not improve from 0.18613\n","Epoch 140/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.7346 - precision_5: 0.6559 - recall_5: 0.7305 - val_loss: 0.1931 - val_accuracy: 0.7011 - val_precision_5: 0.6205 - val_recall_5: 0.7473\n","\n","Epoch 00140: val_loss did not improve from 0.18613\n","Epoch 141/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7350 - precision_5: 0.6567 - recall_5: 0.7305 - val_loss: 0.1864 - val_accuracy: 0.7142 - val_precision_5: 0.6598 - val_recall_5: 0.6634\n","\n","Epoch 00141: val_loss did not improve from 0.18613\n","Epoch 142/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7327 - precision_5: 0.6546 - recall_5: 0.7291 - val_loss: 0.1888 - val_accuracy: 0.7117 - val_precision_5: 0.6436 - val_recall_5: 0.7066\n","\n","Epoch 00142: val_loss did not improve from 0.18613\n","Epoch 143/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7351 - precision_5: 0.6616 - recall_5: 0.7411 - val_loss: 0.1874 - val_accuracy: 0.7122 - val_precision_5: 0.6486 - val_recall_5: 0.6910\n","\n","Epoch 00143: val_loss did not improve from 0.18613\n","Epoch 144/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7361 - precision_5: 0.6617 - recall_5: 0.7284 - val_loss: 0.1895 - val_accuracy: 0.7102 - val_precision_5: 0.6399 - val_recall_5: 0.7130\n","\n","Epoch 00144: val_loss did not improve from 0.18613\n","Epoch 145/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7335 - precision_5: 0.6573 - recall_5: 0.7296 - val_loss: 0.1872 - val_accuracy: 0.7136 - val_precision_5: 0.6536 - val_recall_5: 0.6802\n","\n","Epoch 00145: val_loss did not improve from 0.18613\n","Epoch 146/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.7322 - precision_5: 0.6546 - recall_5: 0.7259 - val_loss: 0.1908 - val_accuracy: 0.7085 - val_precision_5: 0.6332 - val_recall_5: 0.7314\n","\n","Epoch 00146: val_loss did not improve from 0.18613\n","Epoch 147/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.7329 - precision_5: 0.6550 - recall_5: 0.7350 - val_loss: 0.1900 - val_accuracy: 0.7075 - val_precision_5: 0.6346 - val_recall_5: 0.7203\n","\n","Epoch 00147: val_loss did not improve from 0.18613\n","Epoch 148/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.7386 - precision_5: 0.6622 - recall_5: 0.7317 - val_loss: 0.1889 - val_accuracy: 0.7091 - val_precision_5: 0.6411 - val_recall_5: 0.7025\n","\n","Epoch 00148: val_loss did not improve from 0.18613\n","Epoch 149/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1775 - accuracy: 0.7364 - precision_5: 0.6592 - recall_5: 0.7404 - val_loss: 0.1883 - val_accuracy: 0.7103 - val_precision_5: 0.6442 - val_recall_5: 0.6971\n","\n","Epoch 00149: val_loss did not improve from 0.18613\n","Epoch 150/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7401 - precision_5: 0.6638 - recall_5: 0.7345 - val_loss: 0.1900 - val_accuracy: 0.7089 - val_precision_5: 0.6361 - val_recall_5: 0.7212\n","\n","Epoch 00150: val_loss did not improve from 0.18613\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy: 0.7006103437198844\n","Recall: 0.6162764771460424\n","Specificity: 0.7199791612399062\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rwfzXJ9PxDps"},"source":["#### Feature Reduction for ANN Classifier\n","\n","Following Model Has 42 features, reduced from 49 earlier"]},{"cell_type":"code","metadata":{"id":"6G2wabyqlu8y"},"source":["myData_reduced_42 = myData.drop([\"ARRIVAL_MODE_Air Ambulance\",'PTN_AGE_>100',\"Labs_Ordered_Hour_After_Arrival\",\n","                          \"Number_of_Patients_In_Waiting_Before_CTAS\",\"Number_of_Patients_In_Waiting_Before\",\n","                          \"PTN_AGE_1-10\",\"INIT_LOC_GRP_WR Non ED\"],axis=1)\n","Xtrain_42, Xtest_42, yTrain_42, yTest_42 = splitIntoTrainTest(myData_reduced_42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTpAtyORw59n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617560783200,"user_tz":360,"elapsed":217410,"user":{"displayName":"Sim Bhattarai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpaBPF0DuLN5KkInccG6Ttqk5D8haa72YxXR_6=s64","userId":"11084487050159240062"}},"outputId":"a587cbe5-278c-4be9-edaf-380422cc7721"},"source":["model_42 = buildModel(42)\n","fitModel(myData_reduced_42, model_42,  Xtrain_42, yTrain_42, Xtest_42, yTest_42)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","598/598 [==============================] - 3s 3ms/step - loss: 0.2505 - accuracy: 0.4227 - precision_6: 0.4131 - recall_6: 0.9635 - val_loss: 0.2495 - val_accuracy: 0.5201 - val_precision_6: 0.4586 - val_recall_6: 0.7964\n","\n","Epoch 00001: val_loss improved from inf to 0.24951, saving model to Test1.h5\n","Epoch 2/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.5456 - precision_6: 0.4702 - recall_6: 0.7556 - val_loss: 0.2398 - val_accuracy: 0.6046 - val_precision_6: 0.5247 - val_recall_6: 0.6091\n","\n","Epoch 00002: val_loss improved from 0.24951 to 0.23984, saving model to Test1.h5\n","Epoch 3/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2360 - accuracy: 0.6030 - precision_6: 0.5107 - recall_6: 0.6153 - val_loss: 0.2291 - val_accuracy: 0.6185 - val_precision_6: 0.5391 - val_recall_6: 0.6254\n","\n","Epoch 00003: val_loss improved from 0.23984 to 0.22907, saving model to Test1.h5\n","Epoch 4/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2280 - accuracy: 0.6162 - precision_6: 0.5311 - recall_6: 0.6506 - val_loss: 0.2204 - val_accuracy: 0.6381 - val_precision_6: 0.5704 - val_recall_6: 0.5558\n","\n","Epoch 00004: val_loss improved from 0.22907 to 0.22041, saving model to Test1.h5\n","Epoch 5/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2216 - accuracy: 0.6384 - precision_6: 0.5562 - recall_6: 0.6471 - val_loss: 0.2177 - val_accuracy: 0.6481 - val_precision_6: 0.5775 - val_recall_6: 0.6005\n","\n","Epoch 00005: val_loss improved from 0.22041 to 0.21767, saving model to Test1.h5\n","Epoch 6/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2180 - accuracy: 0.6481 - precision_6: 0.5658 - recall_6: 0.6561 - val_loss: 0.2156 - val_accuracy: 0.6557 - val_precision_6: 0.5834 - val_recall_6: 0.6270\n","\n","Epoch 00006: val_loss improved from 0.21767 to 0.21565, saving model to Test1.h5\n","Epoch 7/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2168 - accuracy: 0.6564 - precision_6: 0.5772 - recall_6: 0.6505 - val_loss: 0.2142 - val_accuracy: 0.6602 - val_precision_6: 0.5862 - val_recall_6: 0.6455\n","\n","Epoch 00007: val_loss improved from 0.21565 to 0.21415, saving model to Test1.h5\n","Epoch 8/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2142 - accuracy: 0.6655 - precision_6: 0.5827 - recall_6: 0.6539 - val_loss: 0.2140 - val_accuracy: 0.6589 - val_precision_6: 0.5796 - val_recall_6: 0.6809\n","\n","Epoch 00008: val_loss improved from 0.21415 to 0.21400, saving model to Test1.h5\n","Epoch 9/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2117 - accuracy: 0.6720 - precision_6: 0.5901 - recall_6: 0.6612 - val_loss: 0.2127 - val_accuracy: 0.6624 - val_precision_6: 0.5817 - val_recall_6: 0.6950\n","\n","Epoch 00009: val_loss improved from 0.21400 to 0.21273, saving model to Test1.h5\n","Epoch 10/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2096 - accuracy: 0.6718 - precision_6: 0.5917 - recall_6: 0.6738 - val_loss: 0.2063 - val_accuracy: 0.6784 - val_precision_6: 0.6211 - val_recall_6: 0.5980\n","\n","Epoch 00010: val_loss improved from 0.21273 to 0.20625, saving model to Test1.h5\n","Epoch 11/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2083 - accuracy: 0.6798 - precision_6: 0.6020 - recall_6: 0.6681 - val_loss: 0.2050 - val_accuracy: 0.6808 - val_precision_6: 0.6235 - val_recall_6: 0.6034\n","\n","Epoch 00011: val_loss improved from 0.20625 to 0.20497, saving model to Test1.h5\n","Epoch 12/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2078 - accuracy: 0.6781 - precision_6: 0.6025 - recall_6: 0.6711 - val_loss: 0.2112 - val_accuracy: 0.6632 - val_precision_6: 0.5797 - val_recall_6: 0.7173\n","\n","Epoch 00012: val_loss did not improve from 0.20497\n","Epoch 13/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2057 - accuracy: 0.6817 - precision_6: 0.6019 - recall_6: 0.6776 - val_loss: 0.2065 - val_accuracy: 0.6750 - val_precision_6: 0.6011 - val_recall_6: 0.6694\n","\n","Epoch 00013: val_loss did not improve from 0.20497\n","Epoch 14/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2061 - accuracy: 0.6825 - precision_6: 0.6039 - recall_6: 0.6709 - val_loss: 0.2042 - val_accuracy: 0.6813 - val_precision_6: 0.6127 - val_recall_6: 0.6532\n","\n","Epoch 00014: val_loss improved from 0.20497 to 0.20417, saving model to Test1.h5\n","Epoch 15/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2036 - accuracy: 0.6869 - precision_6: 0.6078 - recall_6: 0.6725 - val_loss: 0.2017 - val_accuracy: 0.6867 - val_precision_6: 0.6278 - val_recall_6: 0.6216\n","\n","Epoch 00015: val_loss improved from 0.20417 to 0.20175, saving model to Test1.h5\n","Epoch 16/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2019 - accuracy: 0.6962 - precision_6: 0.6190 - recall_6: 0.6761 - val_loss: 0.2072 - val_accuracy: 0.6738 - val_precision_6: 0.5937 - val_recall_6: 0.7045\n","\n","Epoch 00016: val_loss did not improve from 0.20175\n","Epoch 17/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2032 - accuracy: 0.6883 - precision_6: 0.6081 - recall_6: 0.6745 - val_loss: 0.2033 - val_accuracy: 0.6828 - val_precision_6: 0.6113 - val_recall_6: 0.6694\n","\n","Epoch 00017: val_loss did not improve from 0.20175\n","Epoch 18/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2026 - accuracy: 0.6868 - precision_6: 0.6074 - recall_6: 0.6754 - val_loss: 0.2066 - val_accuracy: 0.6717 - val_precision_6: 0.5902 - val_recall_6: 0.7112\n","\n","Epoch 00018: val_loss did not improve from 0.20175\n","Epoch 19/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2010 - accuracy: 0.6889 - precision_6: 0.6129 - recall_6: 0.6940 - val_loss: 0.2031 - val_accuracy: 0.6794 - val_precision_6: 0.6058 - val_recall_6: 0.6752\n","\n","Epoch 00019: val_loss did not improve from 0.20175\n","Epoch 20/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2027 - accuracy: 0.6861 - precision_6: 0.6100 - recall_6: 0.6810 - val_loss: 0.1998 - val_accuracy: 0.6909 - val_precision_6: 0.6307 - val_recall_6: 0.6353\n","\n","Epoch 00020: val_loss improved from 0.20175 to 0.19976, saving model to Test1.h5\n","Epoch 21/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2002 - accuracy: 0.6959 - precision_6: 0.6221 - recall_6: 0.6869 - val_loss: 0.1996 - val_accuracy: 0.6887 - val_precision_6: 0.6263 - val_recall_6: 0.6391\n","\n","Epoch 00021: val_loss improved from 0.19976 to 0.19956, saving model to Test1.h5\n","Epoch 22/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.7003 - precision_6: 0.6211 - recall_6: 0.6801 - val_loss: 0.1993 - val_accuracy: 0.6873 - val_precision_6: 0.6241 - val_recall_6: 0.6401\n","\n","Epoch 00022: val_loss improved from 0.19956 to 0.19931, saving model to Test1.h5\n","Epoch 23/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.6949 - precision_6: 0.6159 - recall_6: 0.6738 - val_loss: 0.1997 - val_accuracy: 0.6864 - val_precision_6: 0.6205 - val_recall_6: 0.6500\n","\n","Epoch 00023: val_loss did not improve from 0.19931\n","Epoch 24/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1983 - accuracy: 0.6960 - precision_6: 0.6165 - recall_6: 0.6840 - val_loss: 0.2071 - val_accuracy: 0.6745 - val_precision_6: 0.5890 - val_recall_6: 0.7415\n","\n","Epoch 00024: val_loss did not improve from 0.19931\n","Epoch 25/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1986 - accuracy: 0.6964 - precision_6: 0.6150 - recall_6: 0.6923 - val_loss: 0.2053 - val_accuracy: 0.6774 - val_precision_6: 0.5951 - val_recall_6: 0.7230\n","\n","Epoch 00025: val_loss did not improve from 0.19931\n","Epoch 26/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1973 - accuracy: 0.6939 - precision_6: 0.6143 - recall_6: 0.6833 - val_loss: 0.1996 - val_accuracy: 0.6867 - val_precision_6: 0.6175 - val_recall_6: 0.6650\n","\n","Epoch 00026: val_loss did not improve from 0.19931\n","Epoch 27/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1954 - accuracy: 0.6983 - precision_6: 0.6202 - recall_6: 0.6971 - val_loss: 0.2018 - val_accuracy: 0.6825 - val_precision_6: 0.6050 - val_recall_6: 0.7004\n","\n","Epoch 00027: val_loss did not improve from 0.19931\n","Epoch 28/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1982 - accuracy: 0.6955 - precision_6: 0.6182 - recall_6: 0.6925 - val_loss: 0.2055 - val_accuracy: 0.6749 - val_precision_6: 0.5907 - val_recall_6: 0.7323\n","\n","Epoch 00028: val_loss did not improve from 0.19931\n","Epoch 29/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.6979 - precision_6: 0.6188 - recall_6: 0.6892 - val_loss: 0.1980 - val_accuracy: 0.6921 - val_precision_6: 0.6274 - val_recall_6: 0.6551\n","\n","Epoch 00029: val_loss improved from 0.19931 to 0.19798, saving model to Test1.h5\n","Epoch 30/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1960 - accuracy: 0.7032 - precision_6: 0.6298 - recall_6: 0.6894 - val_loss: 0.2023 - val_accuracy: 0.6822 - val_precision_6: 0.6035 - val_recall_6: 0.7068\n","\n","Epoch 00030: val_loss did not improve from 0.19798\n","Epoch 31/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.7059 - precision_6: 0.6281 - recall_6: 0.7021 - val_loss: 0.1970 - val_accuracy: 0.6954 - val_precision_6: 0.6349 - val_recall_6: 0.6442\n","\n","Epoch 00031: val_loss improved from 0.19798 to 0.19704, saving model to Test1.h5\n","Epoch 32/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.7036 - precision_6: 0.6257 - recall_6: 0.6860 - val_loss: 0.1975 - val_accuracy: 0.6928 - val_precision_6: 0.6298 - val_recall_6: 0.6493\n","\n","Epoch 00032: val_loss did not improve from 0.19704\n","Epoch 33/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1934 - accuracy: 0.7061 - precision_6: 0.6326 - recall_6: 0.6941 - val_loss: 0.1987 - val_accuracy: 0.6896 - val_precision_6: 0.6195 - val_recall_6: 0.6739\n","\n","Epoch 00033: val_loss did not improve from 0.19704\n","Epoch 34/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1927 - accuracy: 0.7096 - precision_6: 0.6284 - recall_6: 0.6911 - val_loss: 0.1973 - val_accuracy: 0.6931 - val_precision_6: 0.6283 - val_recall_6: 0.6570\n","\n","Epoch 00034: val_loss did not improve from 0.19704\n","Epoch 35/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1932 - accuracy: 0.7103 - precision_6: 0.6349 - recall_6: 0.6967 - val_loss: 0.1980 - val_accuracy: 0.6959 - val_precision_6: 0.6283 - val_recall_6: 0.6736\n","\n","Epoch 00035: val_loss did not improve from 0.19704\n","Epoch 36/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1940 - accuracy: 0.7032 - precision_6: 0.6234 - recall_6: 0.6925 - val_loss: 0.1969 - val_accuracy: 0.6943 - val_precision_6: 0.6314 - val_recall_6: 0.6516\n","\n","Epoch 00036: val_loss improved from 0.19704 to 0.19690, saving model to Test1.h5\n","Epoch 37/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.7032 - precision_6: 0.6292 - recall_6: 0.6952 - val_loss: 0.1948 - val_accuracy: 0.7014 - val_precision_6: 0.6544 - val_recall_6: 0.6107\n","\n","Epoch 00037: val_loss improved from 0.19690 to 0.19475, saving model to Test1.h5\n","Epoch 38/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1918 - accuracy: 0.7067 - precision_6: 0.6328 - recall_6: 0.6929 - val_loss: 0.2057 - val_accuracy: 0.6746 - val_precision_6: 0.5879 - val_recall_6: 0.7505\n","\n","Epoch 00038: val_loss did not improve from 0.19475\n","Epoch 39/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.7096 - precision_6: 0.6351 - recall_6: 0.7093 - val_loss: 0.1963 - val_accuracy: 0.6970 - val_precision_6: 0.6340 - val_recall_6: 0.6567\n","\n","Epoch 00039: val_loss did not improve from 0.19475\n","Epoch 40/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1919 - accuracy: 0.7103 - precision_6: 0.6349 - recall_6: 0.7029 - val_loss: 0.1978 - val_accuracy: 0.6932 - val_precision_6: 0.6232 - val_recall_6: 0.6793\n","\n","Epoch 00040: val_loss did not improve from 0.19475\n","Epoch 41/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1908 - accuracy: 0.7127 - precision_6: 0.6398 - recall_6: 0.7016 - val_loss: 0.1966 - val_accuracy: 0.6967 - val_precision_6: 0.6314 - val_recall_6: 0.6656\n","\n","Epoch 00041: val_loss did not improve from 0.19475\n","Epoch 42/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.7070 - precision_6: 0.6277 - recall_6: 0.6950 - val_loss: 0.1981 - val_accuracy: 0.6946 - val_precision_6: 0.6250 - val_recall_6: 0.6796\n","\n","Epoch 00042: val_loss did not improve from 0.19475\n","Epoch 43/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1917 - accuracy: 0.7105 - precision_6: 0.6359 - recall_6: 0.7094 - val_loss: 0.1975 - val_accuracy: 0.6967 - val_precision_6: 0.6276 - val_recall_6: 0.6812\n","\n","Epoch 00043: val_loss did not improve from 0.19475\n","Epoch 44/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.7150 - precision_6: 0.6410 - recall_6: 0.7022 - val_loss: 0.1963 - val_accuracy: 0.6960 - val_precision_6: 0.6310 - val_recall_6: 0.6634\n","\n","Epoch 00044: val_loss did not improve from 0.19475\n","Epoch 45/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1918 - accuracy: 0.7102 - precision_6: 0.6381 - recall_6: 0.7053 - val_loss: 0.1957 - val_accuracy: 0.6990 - val_precision_6: 0.6364 - val_recall_6: 0.6586\n","\n","Epoch 00045: val_loss did not improve from 0.19475\n","Epoch 46/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.7113 - precision_6: 0.6381 - recall_6: 0.7036 - val_loss: 0.1956 - val_accuracy: 0.7000 - val_precision_6: 0.6389 - val_recall_6: 0.6554\n","\n","Epoch 00046: val_loss did not improve from 0.19475\n","Epoch 47/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.7129 - precision_6: 0.6392 - recall_6: 0.6979 - val_loss: 0.2010 - val_accuracy: 0.6888 - val_precision_6: 0.6085 - val_recall_6: 0.7237\n","\n","Epoch 00047: val_loss did not improve from 0.19475\n","Epoch 48/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.7111 - precision_6: 0.6336 - recall_6: 0.7124 - val_loss: 0.1933 - val_accuracy: 0.7029 - val_precision_6: 0.6642 - val_recall_6: 0.5900\n","\n","Epoch 00048: val_loss improved from 0.19475 to 0.19334, saving model to Test1.h5\n","Epoch 49/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.7169 - precision_6: 0.6426 - recall_6: 0.7037 - val_loss: 0.1990 - val_accuracy: 0.6933 - val_precision_6: 0.6171 - val_recall_6: 0.7087\n","\n","Epoch 00049: val_loss did not improve from 0.19334\n","Epoch 50/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1887 - accuracy: 0.7172 - precision_6: 0.6386 - recall_6: 0.7019 - val_loss: 0.1952 - val_accuracy: 0.7004 - val_precision_6: 0.6390 - val_recall_6: 0.6573\n","\n","Epoch 00050: val_loss did not improve from 0.19334\n","Epoch 51/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1880 - accuracy: 0.7201 - precision_6: 0.6461 - recall_6: 0.7063 - val_loss: 0.1981 - val_accuracy: 0.6933 - val_precision_6: 0.6196 - val_recall_6: 0.6966\n","\n","Epoch 00051: val_loss did not improve from 0.19334\n","Epoch 52/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1885 - accuracy: 0.7167 - precision_6: 0.6438 - recall_6: 0.7130 - val_loss: 0.1939 - val_accuracy: 0.7029 - val_precision_6: 0.6498 - val_recall_6: 0.6324\n","\n","Epoch 00052: val_loss did not improve from 0.19334\n","Epoch 53/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.7194 - precision_6: 0.6467 - recall_6: 0.7078 - val_loss: 0.1927 - val_accuracy: 0.7049 - val_precision_6: 0.6661 - val_recall_6: 0.5944\n","\n","Epoch 00053: val_loss improved from 0.19334 to 0.19275, saving model to Test1.h5\n","Epoch 54/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1887 - accuracy: 0.7176 - precision_6: 0.6472 - recall_6: 0.7024 - val_loss: 0.1935 - val_accuracy: 0.7012 - val_precision_6: 0.6491 - val_recall_6: 0.6264\n","\n","Epoch 00054: val_loss did not improve from 0.19275\n","Epoch 55/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1908 - accuracy: 0.7100 - precision_6: 0.6352 - recall_6: 0.7086 - val_loss: 0.1995 - val_accuracy: 0.6909 - val_precision_6: 0.6126 - val_recall_6: 0.7160\n","\n","Epoch 00055: val_loss did not improve from 0.19275\n","Epoch 56/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.7204 - precision_6: 0.6471 - recall_6: 0.7154 - val_loss: 0.1989 - val_accuracy: 0.6913 - val_precision_6: 0.6140 - val_recall_6: 0.7116\n","\n","Epoch 00056: val_loss did not improve from 0.19275\n","Epoch 57/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1885 - accuracy: 0.7196 - precision_6: 0.6442 - recall_6: 0.7121 - val_loss: 0.1988 - val_accuracy: 0.6924 - val_precision_6: 0.6152 - val_recall_6: 0.7125\n","\n","Epoch 00057: val_loss did not improve from 0.19275\n","Epoch 58/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.7129 - precision_6: 0.6407 - recall_6: 0.7074 - val_loss: 0.2033 - val_accuracy: 0.6844 - val_precision_6: 0.5986 - val_recall_6: 0.7514\n","\n","Epoch 00058: val_loss did not improve from 0.19275\n","Epoch 59/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.7211 - precision_6: 0.6415 - recall_6: 0.7178 - val_loss: 0.1950 - val_accuracy: 0.7031 - val_precision_6: 0.6398 - val_recall_6: 0.6688\n","\n","Epoch 00059: val_loss did not improve from 0.19275\n","Epoch 60/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1880 - accuracy: 0.7171 - precision_6: 0.6418 - recall_6: 0.7099 - val_loss: 0.1955 - val_accuracy: 0.7011 - val_precision_6: 0.6336 - val_recall_6: 0.6816\n","\n","Epoch 00060: val_loss did not improve from 0.19275\n","Epoch 61/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1882 - accuracy: 0.7171 - precision_6: 0.6416 - recall_6: 0.7109 - val_loss: 0.1953 - val_accuracy: 0.7004 - val_precision_6: 0.6348 - val_recall_6: 0.6733\n","\n","Epoch 00061: val_loss did not improve from 0.19275\n","Epoch 62/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.7254 - precision_6: 0.6493 - recall_6: 0.7113 - val_loss: 0.1966 - val_accuracy: 0.6990 - val_precision_6: 0.6265 - val_recall_6: 0.6994\n","\n","Epoch 00062: val_loss did not improve from 0.19275\n","Epoch 63/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1882 - accuracy: 0.7157 - precision_6: 0.6411 - recall_6: 0.7074 - val_loss: 0.1984 - val_accuracy: 0.6955 - val_precision_6: 0.6185 - val_recall_6: 0.7154\n","\n","Epoch 00063: val_loss did not improve from 0.19275\n","Epoch 64/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.7222 - precision_6: 0.6478 - recall_6: 0.7203 - val_loss: 0.1956 - val_accuracy: 0.6991 - val_precision_6: 0.6302 - val_recall_6: 0.6841\n","\n","Epoch 00064: val_loss did not improve from 0.19275\n","Epoch 65/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.7171 - precision_6: 0.6424 - recall_6: 0.7166 - val_loss: 0.1948 - val_accuracy: 0.7018 - val_precision_6: 0.6365 - val_recall_6: 0.6739\n","\n","Epoch 00065: val_loss did not improve from 0.19275\n","Epoch 66/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1844 - accuracy: 0.7297 - precision_6: 0.6538 - recall_6: 0.7197 - val_loss: 0.2040 - val_accuracy: 0.6833 - val_precision_6: 0.5959 - val_recall_6: 0.7613\n","\n","Epoch 00066: val_loss did not improve from 0.19275\n","Epoch 67/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.7217 - precision_6: 0.6485 - recall_6: 0.7300 - val_loss: 0.1940 - val_accuracy: 0.7035 - val_precision_6: 0.6430 - val_recall_6: 0.6592\n","\n","Epoch 00067: val_loss did not improve from 0.19275\n","Epoch 68/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1878 - accuracy: 0.7188 - precision_6: 0.6443 - recall_6: 0.7176 - val_loss: 0.2001 - val_accuracy: 0.6907 - val_precision_6: 0.6100 - val_recall_6: 0.7281\n","\n","Epoch 00068: val_loss did not improve from 0.19275\n","Epoch 69/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.7194 - precision_6: 0.6470 - recall_6: 0.7152 - val_loss: 0.1956 - val_accuracy: 0.7015 - val_precision_6: 0.6328 - val_recall_6: 0.6873\n","\n","Epoch 00069: val_loss did not improve from 0.19275\n","Epoch 70/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1877 - accuracy: 0.7217 - precision_6: 0.6469 - recall_6: 0.7134 - val_loss: 0.1973 - val_accuracy: 0.6978 - val_precision_6: 0.6234 - val_recall_6: 0.7058\n","\n","Epoch 00070: val_loss did not improve from 0.19275\n","Epoch 71/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1857 - accuracy: 0.7225 - precision_6: 0.6496 - recall_6: 0.7225 - val_loss: 0.1986 - val_accuracy: 0.6937 - val_precision_6: 0.6152 - val_recall_6: 0.7208\n","\n","Epoch 00071: val_loss did not improve from 0.19275\n","Epoch 72/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.7144 - precision_6: 0.6419 - recall_6: 0.7186 - val_loss: 0.1980 - val_accuracy: 0.6937 - val_precision_6: 0.6176 - val_recall_6: 0.7087\n","\n","Epoch 00072: val_loss did not improve from 0.19275\n","Epoch 73/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1875 - accuracy: 0.7154 - precision_6: 0.6381 - recall_6: 0.7075 - val_loss: 0.1932 - val_accuracy: 0.7057 - val_precision_6: 0.6481 - val_recall_6: 0.6528\n","\n","Epoch 00073: val_loss did not improve from 0.19275\n","Epoch 74/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.7221 - precision_6: 0.6499 - recall_6: 0.7117 - val_loss: 0.1949 - val_accuracy: 0.7016 - val_precision_6: 0.6343 - val_recall_6: 0.6819\n","\n","Epoch 00074: val_loss did not improve from 0.19275\n","Epoch 75/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1859 - accuracy: 0.7234 - precision_6: 0.6514 - recall_6: 0.7191 - val_loss: 0.2016 - val_accuracy: 0.6864 - val_precision_6: 0.6030 - val_recall_6: 0.7390\n","\n","Epoch 00075: val_loss did not improve from 0.19275\n","Epoch 76/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.7207 - precision_6: 0.6461 - recall_6: 0.7255 - val_loss: 0.1922 - val_accuracy: 0.7049 - val_precision_6: 0.6544 - val_recall_6: 0.6283\n","\n","Epoch 00076: val_loss improved from 0.19275 to 0.19216, saving model to Test1.h5\n","Epoch 77/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1875 - accuracy: 0.7178 - precision_6: 0.6447 - recall_6: 0.7161 - val_loss: 0.1942 - val_accuracy: 0.7041 - val_precision_6: 0.6402 - val_recall_6: 0.6723\n","\n","Epoch 00077: val_loss did not improve from 0.19216\n","Epoch 78/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1855 - accuracy: 0.7231 - precision_6: 0.6477 - recall_6: 0.7178 - val_loss: 0.1955 - val_accuracy: 0.7018 - val_precision_6: 0.6315 - val_recall_6: 0.6943\n","\n","Epoch 00078: val_loss did not improve from 0.19216\n","Epoch 79/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1841 - accuracy: 0.7243 - precision_6: 0.6490 - recall_6: 0.7228 - val_loss: 0.1961 - val_accuracy: 0.6975 - val_precision_6: 0.6254 - val_recall_6: 0.6956\n","\n","Epoch 00079: val_loss did not improve from 0.19216\n","Epoch 80/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1843 - accuracy: 0.7252 - precision_6: 0.6518 - recall_6: 0.7217 - val_loss: 0.1947 - val_accuracy: 0.7037 - val_precision_6: 0.6359 - val_recall_6: 0.6867\n","\n","Epoch 00080: val_loss did not improve from 0.19216\n","Epoch 81/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.7197 - precision_6: 0.6414 - recall_6: 0.7075 - val_loss: 0.1917 - val_accuracy: 0.7069 - val_precision_6: 0.6682 - val_recall_6: 0.5983\n","\n","Epoch 00081: val_loss improved from 0.19216 to 0.19167, saving model to Test1.h5\n","Epoch 82/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1837 - accuracy: 0.7301 - precision_6: 0.6529 - recall_6: 0.7184 - val_loss: 0.1976 - val_accuracy: 0.6947 - val_precision_6: 0.6180 - val_recall_6: 0.7128\n","\n","Epoch 00082: val_loss did not improve from 0.19167\n","Epoch 83/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1851 - accuracy: 0.7230 - precision_6: 0.6469 - recall_6: 0.7242 - val_loss: 0.1950 - val_accuracy: 0.6999 - val_precision_6: 0.6308 - val_recall_6: 0.6863\n","\n","Epoch 00083: val_loss did not improve from 0.19167\n","Epoch 84/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1855 - accuracy: 0.7217 - precision_6: 0.6472 - recall_6: 0.7221 - val_loss: 0.1991 - val_accuracy: 0.6920 - val_precision_6: 0.6114 - val_recall_6: 0.7294\n","\n","Epoch 00084: val_loss did not improve from 0.19167\n","Epoch 85/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1842 - accuracy: 0.7272 - precision_6: 0.6523 - recall_6: 0.7230 - val_loss: 0.1988 - val_accuracy: 0.6937 - val_precision_6: 0.6143 - val_recall_6: 0.7256\n","\n","Epoch 00085: val_loss did not improve from 0.19167\n","Epoch 86/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1842 - accuracy: 0.7266 - precision_6: 0.6527 - recall_6: 0.7230 - val_loss: 0.2007 - val_accuracy: 0.6887 - val_precision_6: 0.6049 - val_recall_6: 0.7435\n","\n","Epoch 00086: val_loss did not improve from 0.19167\n","Epoch 87/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.7210 - precision_6: 0.6421 - recall_6: 0.7266 - val_loss: 0.1947 - val_accuracy: 0.7039 - val_precision_6: 0.6365 - val_recall_6: 0.6860\n","\n","Epoch 00087: val_loss did not improve from 0.19167\n","Epoch 88/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.7253 - precision_6: 0.6480 - recall_6: 0.7175 - val_loss: 0.1945 - val_accuracy: 0.7023 - val_precision_6: 0.6353 - val_recall_6: 0.6819\n","\n","Epoch 00088: val_loss did not improve from 0.19167\n","Epoch 89/150\n","598/598 [==============================] - 1s 3ms/step - loss: 0.1847 - accuracy: 0.7232 - precision_6: 0.6495 - recall_6: 0.7206 - val_loss: 0.2007 - val_accuracy: 0.6889 - val_precision_6: 0.6046 - val_recall_6: 0.7470\n","\n","Epoch 00089: val_loss did not improve from 0.19167\n","Epoch 90/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1849 - accuracy: 0.7233 - precision_6: 0.6449 - recall_6: 0.7235 - val_loss: 0.1978 - val_accuracy: 0.6963 - val_precision_6: 0.6190 - val_recall_6: 0.7176\n","\n","Epoch 00090: val_loss did not improve from 0.19167\n","Epoch 91/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1844 - accuracy: 0.7224 - precision_6: 0.6477 - recall_6: 0.7302 - val_loss: 0.1936 - val_accuracy: 0.7053 - val_precision_6: 0.6422 - val_recall_6: 0.6717\n","\n","Epoch 00091: val_loss did not improve from 0.19167\n","Epoch 92/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.7292 - precision_6: 0.6552 - recall_6: 0.7252 - val_loss: 0.1972 - val_accuracy: 0.6966 - val_precision_6: 0.6195 - val_recall_6: 0.7170\n","\n","Epoch 00092: val_loss did not improve from 0.19167\n","Epoch 93/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1829 - accuracy: 0.7272 - precision_6: 0.6510 - recall_6: 0.7279 - val_loss: 0.1998 - val_accuracy: 0.6904 - val_precision_6: 0.6084 - val_recall_6: 0.7352\n","\n","Epoch 00093: val_loss did not improve from 0.19167\n","Epoch 94/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.7284 - precision_6: 0.6520 - recall_6: 0.7226 - val_loss: 0.1943 - val_accuracy: 0.7010 - val_precision_6: 0.6337 - val_recall_6: 0.6806\n","\n","Epoch 00094: val_loss did not improve from 0.19167\n","Epoch 95/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.7277 - precision_6: 0.6529 - recall_6: 0.7273 - val_loss: 0.1976 - val_accuracy: 0.6964 - val_precision_6: 0.6200 - val_recall_6: 0.7138\n","\n","Epoch 00095: val_loss did not improve from 0.19167\n","Epoch 96/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1837 - accuracy: 0.7258 - precision_6: 0.6487 - recall_6: 0.7247 - val_loss: 0.1937 - val_accuracy: 0.7050 - val_precision_6: 0.6413 - val_recall_6: 0.6736\n","\n","Epoch 00096: val_loss did not improve from 0.19167\n","Epoch 97/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.7297 - precision_6: 0.6522 - recall_6: 0.7267 - val_loss: 0.1924 - val_accuracy: 0.7066 - val_precision_6: 0.6532 - val_recall_6: 0.6407\n","\n","Epoch 00097: val_loss did not improve from 0.19167\n","Epoch 98/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1820 - accuracy: 0.7275 - precision_6: 0.6488 - recall_6: 0.7240 - val_loss: 0.1952 - val_accuracy: 0.7008 - val_precision_6: 0.6296 - val_recall_6: 0.6969\n","\n","Epoch 00098: val_loss did not improve from 0.19167\n","Epoch 99/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1831 - accuracy: 0.7273 - precision_6: 0.6533 - recall_6: 0.7308 - val_loss: 0.1925 - val_accuracy: 0.7065 - val_precision_6: 0.6512 - val_recall_6: 0.6465\n","\n","Epoch 00099: val_loss did not improve from 0.19167\n","Epoch 100/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.7281 - precision_6: 0.6561 - recall_6: 0.7332 - val_loss: 0.2049 - val_accuracy: 0.6810 - val_precision_6: 0.5912 - val_recall_6: 0.7770\n","\n","Epoch 00100: val_loss did not improve from 0.19167\n","Epoch 101/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.7272 - precision_6: 0.6486 - recall_6: 0.7265 - val_loss: 0.2005 - val_accuracy: 0.6908 - val_precision_6: 0.6068 - val_recall_6: 0.7470\n","\n","Epoch 00101: val_loss did not improve from 0.19167\n","Epoch 102/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.7296 - precision_6: 0.6531 - recall_6: 0.7325 - val_loss: 0.1940 - val_accuracy: 0.7039 - val_precision_6: 0.6374 - val_recall_6: 0.6825\n","\n","Epoch 00102: val_loss did not improve from 0.19167\n","Epoch 103/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1836 - accuracy: 0.7249 - precision_6: 0.6465 - recall_6: 0.7238 - val_loss: 0.1944 - val_accuracy: 0.7011 - val_precision_6: 0.6319 - val_recall_6: 0.6886\n","\n","Epoch 00103: val_loss did not improve from 0.19167\n","Epoch 104/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.7273 - precision_6: 0.6526 - recall_6: 0.7336 - val_loss: 0.1921 - val_accuracy: 0.7069 - val_precision_6: 0.6528 - val_recall_6: 0.6433\n","\n","Epoch 00104: val_loss did not improve from 0.19167\n","Epoch 105/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.7287 - precision_6: 0.6557 - recall_6: 0.7287 - val_loss: 0.1971 - val_accuracy: 0.6942 - val_precision_6: 0.6170 - val_recall_6: 0.7144\n","\n","Epoch 00105: val_loss did not improve from 0.19167\n","Epoch 106/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7293 - precision_6: 0.6566 - recall_6: 0.7370 - val_loss: 0.1951 - val_accuracy: 0.7015 - val_precision_6: 0.6299 - val_recall_6: 0.6994\n","\n","Epoch 00106: val_loss did not improve from 0.19167\n","Epoch 107/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7274 - precision_6: 0.6509 - recall_6: 0.7245 - val_loss: 0.1956 - val_accuracy: 0.6980 - val_precision_6: 0.6262 - val_recall_6: 0.6950\n","\n","Epoch 00107: val_loss did not improve from 0.19167\n","Epoch 108/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.7296 - precision_6: 0.6534 - recall_6: 0.7200 - val_loss: 0.2003 - val_accuracy: 0.6893 - val_precision_6: 0.6066 - val_recall_6: 0.7384\n","\n","Epoch 00108: val_loss did not improve from 0.19167\n","Epoch 109/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1808 - accuracy: 0.7330 - precision_6: 0.6579 - recall_6: 0.7303 - val_loss: 0.1944 - val_accuracy: 0.7041 - val_precision_6: 0.6367 - val_recall_6: 0.6857\n","\n","Epoch 00109: val_loss did not improve from 0.19167\n","Epoch 110/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.7298 - precision_6: 0.6566 - recall_6: 0.7279 - val_loss: 0.1939 - val_accuracy: 0.7022 - val_precision_6: 0.6358 - val_recall_6: 0.6790\n","\n","Epoch 00110: val_loss did not improve from 0.19167\n","Epoch 111/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.7343 - precision_6: 0.6587 - recall_6: 0.7393 - val_loss: 0.1911 - val_accuracy: 0.7049 - val_precision_6: 0.6707 - val_recall_6: 0.5823\n","\n","Epoch 00111: val_loss improved from 0.19167 to 0.19112, saving model to Test1.h5\n","Epoch 112/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.7314 - precision_6: 0.6594 - recall_6: 0.7243 - val_loss: 0.1940 - val_accuracy: 0.7046 - val_precision_6: 0.6389 - val_recall_6: 0.6803\n","\n","Epoch 00112: val_loss did not improve from 0.19112\n","Epoch 113/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.7275 - precision_6: 0.6550 - recall_6: 0.7340 - val_loss: 0.1926 - val_accuracy: 0.7050 - val_precision_6: 0.6460 - val_recall_6: 0.6563\n","\n","Epoch 00113: val_loss did not improve from 0.19112\n","Epoch 114/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1828 - accuracy: 0.7278 - precision_6: 0.6486 - recall_6: 0.7229 - val_loss: 0.1952 - val_accuracy: 0.6994 - val_precision_6: 0.6285 - val_recall_6: 0.6927\n","\n","Epoch 00114: val_loss did not improve from 0.19112\n","Epoch 115/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.7260 - precision_6: 0.6524 - recall_6: 0.7283 - val_loss: 0.1939 - val_accuracy: 0.7031 - val_precision_6: 0.6373 - val_recall_6: 0.6784\n","\n","Epoch 00115: val_loss did not improve from 0.19112\n","Epoch 116/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1805 - accuracy: 0.7331 - precision_6: 0.6586 - recall_6: 0.7319 - val_loss: 0.1933 - val_accuracy: 0.7041 - val_precision_6: 0.6417 - val_recall_6: 0.6669\n","\n","Epoch 00116: val_loss did not improve from 0.19112\n","Epoch 117/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.7264 - precision_6: 0.6521 - recall_6: 0.7246 - val_loss: 0.2014 - val_accuracy: 0.6859 - val_precision_6: 0.5999 - val_recall_6: 0.7537\n","\n","Epoch 00117: val_loss did not improve from 0.19112\n","Epoch 118/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.7312 - precision_6: 0.6538 - recall_6: 0.7387 - val_loss: 0.1951 - val_accuracy: 0.7018 - val_precision_6: 0.6323 - val_recall_6: 0.6908\n","\n","Epoch 00118: val_loss did not improve from 0.19112\n","Epoch 119/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1794 - accuracy: 0.7309 - precision_6: 0.6538 - recall_6: 0.7309 - val_loss: 0.1929 - val_accuracy: 0.7049 - val_precision_6: 0.6456 - val_recall_6: 0.6573\n","\n","Epoch 00119: val_loss did not improve from 0.19112\n","Epoch 120/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.7309 - precision_6: 0.6574 - recall_6: 0.7298 - val_loss: 0.1975 - val_accuracy: 0.6948 - val_precision_6: 0.6171 - val_recall_6: 0.7179\n","\n","Epoch 00120: val_loss did not improve from 0.19112\n","Epoch 121/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7329 - precision_6: 0.6558 - recall_6: 0.7374 - val_loss: 0.1977 - val_accuracy: 0.6917 - val_precision_6: 0.6135 - val_recall_6: 0.7167\n","\n","Epoch 00121: val_loss did not improve from 0.19112\n","Epoch 122/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.7316 - precision_6: 0.6579 - recall_6: 0.7327 - val_loss: 0.1990 - val_accuracy: 0.6908 - val_precision_6: 0.6101 - val_recall_6: 0.7285\n","\n","Epoch 00122: val_loss did not improve from 0.19112\n","Epoch 123/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.7335 - precision_6: 0.6570 - recall_6: 0.7310 - val_loss: 0.1957 - val_accuracy: 0.6987 - val_precision_6: 0.6249 - val_recall_6: 0.7049\n","\n","Epoch 00123: val_loss did not improve from 0.19112\n","Epoch 124/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.7310 - precision_6: 0.6581 - recall_6: 0.7389 - val_loss: 0.1954 - val_accuracy: 0.6988 - val_precision_6: 0.6257 - val_recall_6: 0.7020\n","\n","Epoch 00124: val_loss did not improve from 0.19112\n","Epoch 125/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.7295 - precision_6: 0.6542 - recall_6: 0.7324 - val_loss: 0.1957 - val_accuracy: 0.7006 - val_precision_6: 0.6259 - val_recall_6: 0.7112\n","\n","Epoch 00125: val_loss did not improve from 0.19112\n","Epoch 126/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.7278 - precision_6: 0.6513 - recall_6: 0.7350 - val_loss: 0.1934 - val_accuracy: 0.7035 - val_precision_6: 0.6399 - val_recall_6: 0.6707\n","\n","Epoch 00126: val_loss did not improve from 0.19112\n","Epoch 127/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.7362 - precision_6: 0.6624 - recall_6: 0.7344 - val_loss: 0.1947 - val_accuracy: 0.7031 - val_precision_6: 0.6323 - val_recall_6: 0.6985\n","\n","Epoch 00127: val_loss did not improve from 0.19112\n","Epoch 128/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7327 - precision_6: 0.6556 - recall_6: 0.7383 - val_loss: 0.1962 - val_accuracy: 0.6988 - val_precision_6: 0.6246 - val_recall_6: 0.7068\n","\n","Epoch 00128: val_loss did not improve from 0.19112\n","Epoch 129/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.7289 - precision_6: 0.6495 - recall_6: 0.7355 - val_loss: 0.1942 - val_accuracy: 0.7010 - val_precision_6: 0.6331 - val_recall_6: 0.6832\n","\n","Epoch 00129: val_loss did not improve from 0.19112\n","Epoch 130/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.7305 - precision_6: 0.6567 - recall_6: 0.7243 - val_loss: 0.1982 - val_accuracy: 0.6939 - val_precision_6: 0.6144 - val_recall_6: 0.7256\n","\n","Epoch 00130: val_loss did not improve from 0.19112\n","Epoch 131/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7345 - precision_6: 0.6557 - recall_6: 0.7314 - val_loss: 0.1956 - val_accuracy: 0.6970 - val_precision_6: 0.6236 - val_recall_6: 0.7001\n","\n","Epoch 00131: val_loss did not improve from 0.19112\n","Epoch 132/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1810 - accuracy: 0.7285 - precision_6: 0.6543 - recall_6: 0.7330 - val_loss: 0.1937 - val_accuracy: 0.7027 - val_precision_6: 0.6371 - val_recall_6: 0.6768\n","\n","Epoch 00132: val_loss did not improve from 0.19112\n","Epoch 133/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.7322 - precision_6: 0.6563 - recall_6: 0.7287 - val_loss: 0.1953 - val_accuracy: 0.7006 - val_precision_6: 0.6286 - val_recall_6: 0.6994\n","\n","Epoch 00133: val_loss did not improve from 0.19112\n","Epoch 134/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1798 - accuracy: 0.7333 - precision_6: 0.6587 - recall_6: 0.7286 - val_loss: 0.1964 - val_accuracy: 0.6972 - val_precision_6: 0.6214 - val_recall_6: 0.7119\n","\n","Epoch 00134: val_loss did not improve from 0.19112\n","Epoch 135/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1810 - accuracy: 0.7315 - precision_6: 0.6541 - recall_6: 0.7329 - val_loss: 0.1942 - val_accuracy: 0.6999 - val_precision_6: 0.6313 - val_recall_6: 0.6841\n","\n","Epoch 00135: val_loss did not improve from 0.19112\n","Epoch 136/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.7316 - precision_6: 0.6601 - recall_6: 0.7406 - val_loss: 0.1948 - val_accuracy: 0.6996 - val_precision_6: 0.6291 - val_recall_6: 0.6921\n","\n","Epoch 00136: val_loss did not improve from 0.19112\n","Epoch 137/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.7282 - precision_6: 0.6530 - recall_6: 0.7219 - val_loss: 0.1926 - val_accuracy: 0.7049 - val_precision_6: 0.6459 - val_recall_6: 0.6560\n","\n","Epoch 00137: val_loss did not improve from 0.19112\n","Epoch 138/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.7287 - precision_6: 0.6564 - recall_6: 0.7369 - val_loss: 0.1977 - val_accuracy: 0.6929 - val_precision_6: 0.6143 - val_recall_6: 0.7202\n","\n","Epoch 00138: val_loss did not improve from 0.19112\n","Epoch 139/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7332 - precision_6: 0.6586 - recall_6: 0.7386 - val_loss: 0.1995 - val_accuracy: 0.6897 - val_precision_6: 0.6077 - val_recall_6: 0.7345\n","\n","Epoch 00139: val_loss did not improve from 0.19112\n","Epoch 140/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1807 - accuracy: 0.7308 - precision_6: 0.6574 - recall_6: 0.7387 - val_loss: 0.1965 - val_accuracy: 0.6960 - val_precision_6: 0.6200 - val_recall_6: 0.7116\n","\n","Epoch 00140: val_loss did not improve from 0.19112\n","Epoch 141/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7316 - precision_6: 0.6537 - recall_6: 0.7343 - val_loss: 0.1947 - val_accuracy: 0.7033 - val_precision_6: 0.6327 - val_recall_6: 0.6975\n","\n","Epoch 00141: val_loss did not improve from 0.19112\n","Epoch 142/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1789 - accuracy: 0.7330 - precision_6: 0.6569 - recall_6: 0.7382 - val_loss: 0.1921 - val_accuracy: 0.7050 - val_precision_6: 0.6477 - val_recall_6: 0.6506\n","\n","Epoch 00142: val_loss did not improve from 0.19112\n","Epoch 143/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.7293 - precision_6: 0.6525 - recall_6: 0.7292 - val_loss: 0.1930 - val_accuracy: 0.7034 - val_precision_6: 0.6410 - val_recall_6: 0.6659\n","\n","Epoch 00143: val_loss did not improve from 0.19112\n","Epoch 144/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1811 - accuracy: 0.7320 - precision_6: 0.6564 - recall_6: 0.7273 - val_loss: 0.1946 - val_accuracy: 0.7004 - val_precision_6: 0.6325 - val_recall_6: 0.6825\n","\n","Epoch 00144: val_loss did not improve from 0.19112\n","Epoch 145/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1810 - accuracy: 0.7313 - precision_6: 0.6568 - recall_6: 0.7302 - val_loss: 0.1926 - val_accuracy: 0.7061 - val_precision_6: 0.6441 - val_recall_6: 0.6688\n","\n","Epoch 00145: val_loss did not improve from 0.19112\n","Epoch 146/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7328 - precision_6: 0.6595 - recall_6: 0.7412 - val_loss: 0.1952 - val_accuracy: 0.7000 - val_precision_6: 0.6275 - val_recall_6: 0.7013\n","\n","Epoch 00146: val_loss did not improve from 0.19112\n","Epoch 147/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1806 - accuracy: 0.7319 - precision_6: 0.6609 - recall_6: 0.7320 - val_loss: 0.1941 - val_accuracy: 0.7039 - val_precision_6: 0.6375 - val_recall_6: 0.6819\n","\n","Epoch 00147: val_loss did not improve from 0.19112\n","Epoch 148/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1825 - accuracy: 0.7274 - precision_6: 0.6508 - recall_6: 0.7296 - val_loss: 0.1955 - val_accuracy: 0.7015 - val_precision_6: 0.6283 - val_recall_6: 0.7064\n","\n","Epoch 00148: val_loss did not improve from 0.19112\n","Epoch 149/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1777 - accuracy: 0.7356 - precision_6: 0.6598 - recall_6: 0.7357 - val_loss: 0.1982 - val_accuracy: 0.6948 - val_precision_6: 0.6145 - val_recall_6: 0.7310\n","\n","Epoch 00149: val_loss did not improve from 0.19112\n","Epoch 150/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1791 - accuracy: 0.7327 - precision_6: 0.6612 - recall_6: 0.7393 - val_loss: 0.1934 - val_accuracy: 0.7014 - val_precision_6: 0.6349 - val_recall_6: 0.6780\n","\n","Epoch 00150: val_loss did not improve from 0.19112\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy: 0.7047863796980405\n","Recall: 0.6242053789731051\n","Specificity: 0.6766498807315133\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xGKjR8_-xrrc"},"source":["#### Feature Reduction for ANN Classifier\n","\n","Following Model Has 13 features, reduced from 49 and 42 earlier"]},{"cell_type":"code","metadata":{"id":"fiZImjSkm2ll"},"source":["myData_reduced_13 = myData.drop([\"Number_of_Patients_In_Waiting_Before_CTAS\",\n","                        \"Number_of_Patients_In_Waiting_Before\",\n","                        \"ARRIVAL_MODE_Air Ambulance\",\n","                        \"PTN_AGE_>100\",\n","                        \"PTN_AGE_1-10\",\n","                        \"Labs_Ordered_Hour_After_Arrival\",\n","                        \"INIT_LOC_GRP_WR Non ED\",\n","                        \"Labs_Ordered_Hour_Before_Arrival\",\n","                        \"INIT_LOC_GRP_Intake\",\n","                        \"INIT_LOC_GRP_MET\",\n","                        \"INIT_LOC_GRP_Main\",\n","                        \"DIs_Ordered_Hour_Before_Arrival\",\n","                        \"DIs_Ordered_Hour_After_Arrival\",\n","                        \"PTN_AGE_91-100\",\n","                        \"time_of_day_of_arrival_Morning Dawn\",\n","                        \"time_of_day_of_arrival_Morning Dusk\",\n","                        \"time_of_day_of_arrival_Midday\",\n","                        \"time_of_day_of_arrival_Night/Evening\",\n","                        \"PTN_AGE_11-20\",\n","                        \"INIT_LOC_GRP_WR MET\",\n","                        \"ARRIVAL_MODE_Ground Ambulance\",\n","                        \"PTN_AGE_81-90\",\n","                        \"PTN_AGE_71-80\",\n","                        \"ARRIVAL_MODE_No Ambulance\",\n","                        \"INIT_TREAT_LOC_GRP_Main\",\n","                        \"PTN_AGE_61-70\",\n","                        \"PTN_AGE_51-60\",\n","                        \"PTN_AGE_41-50\",\n","                        \"INIT_LOC_GRP_WR Intake\",\n","                        \"PTN_AGE_21-30\",\n","                        \"PTN_AGE_31-40\",\n","                        \"INIT_LOC_GRP_WR Main\",\n","                        \"INIT_TREAT_LOC_GRP_Intake\",\n","                        \"INIT_TREAT_LOC_GRP_MET\",\n","                        \"PTN_SEX_F\",\n","                        \"PTN_SEX_M\"],axis=1)\n","Xtrain_13, Xtest_13, yTrain_13, yTest_13 = splitIntoTrainTest(myData_reduced_13)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ImBNJKsLyFt1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617564497190,"user_tz":360,"elapsed":229175,"user":{"displayName":"Sim Bhattarai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpaBPF0DuLN5KkInccG6Ttqk5D8haa72YxXR_6=s64","userId":"11084487050159240062"}},"outputId":"2d7035b0-0c8d-46d7-dee6-848b7ec76d2b"},"source":["model_13 = buildModel(13)\n","fitModel(myData_reduced_13, model_13, Xtrain_13, yTrain_13, Xtrain_13, yTrain_13)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","598/598 [==============================] - 3s 3ms/step - loss: 0.2494 - accuracy: 0.4960 - precision_8: 0.4322 - recall_8: 0.7160 - val_loss: 0.2490 - val_accuracy: 0.5529 - val_precision_8: 0.4716 - val_recall_8: 0.7630\n","\n","Epoch 00001: val_loss improved from inf to 0.24899, saving model to Test1.h5\n","Epoch 2/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2473 - accuracy: 0.5666 - precision_8: 0.4814 - recall_8: 0.7237 - val_loss: 0.2440 - val_accuracy: 0.6005 - val_precision_8: 0.5087 - val_recall_8: 0.7077\n","\n","Epoch 00002: val_loss improved from 0.24899 to 0.24404, saving model to Test1.h5\n","Epoch 3/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.5973 - precision_8: 0.5064 - recall_8: 0.6994 - val_loss: 0.2379 - val_accuracy: 0.6049 - val_precision_8: 0.5125 - val_recall_8: 0.7153\n","\n","Epoch 00003: val_loss improved from 0.24404 to 0.23794, saving model to Test1.h5\n","Epoch 4/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2356 - accuracy: 0.6114 - precision_8: 0.5217 - recall_8: 0.7065 - val_loss: 0.2296 - val_accuracy: 0.6299 - val_precision_8: 0.5389 - val_recall_8: 0.6662\n","\n","Epoch 00004: val_loss improved from 0.23794 to 0.22963, saving model to Test1.h5\n","Epoch 5/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2314 - accuracy: 0.6222 - precision_8: 0.5289 - recall_8: 0.6837 - val_loss: 0.2263 - val_accuracy: 0.6379 - val_precision_8: 0.5462 - val_recall_8: 0.6839\n","\n","Epoch 00005: val_loss improved from 0.22963 to 0.22627, saving model to Test1.h5\n","Epoch 6/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2274 - accuracy: 0.6299 - precision_8: 0.5419 - recall_8: 0.6935 - val_loss: 0.2236 - val_accuracy: 0.6452 - val_precision_8: 0.5524 - val_recall_8: 0.7028\n","\n","Epoch 00006: val_loss improved from 0.22627 to 0.22359, saving model to Test1.h5\n","Epoch 7/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2244 - accuracy: 0.6350 - precision_8: 0.5452 - recall_8: 0.6948 - val_loss: 0.2170 - val_accuracy: 0.6568 - val_precision_8: 0.5732 - val_recall_8: 0.6332\n","\n","Epoch 00007: val_loss improved from 0.22359 to 0.21703, saving model to Test1.h5\n","Epoch 8/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2208 - accuracy: 0.6466 - precision_8: 0.5572 - recall_8: 0.6964 - val_loss: 0.2182 - val_accuracy: 0.6587 - val_precision_8: 0.5664 - val_recall_8: 0.7097\n","\n","Epoch 00008: val_loss did not improve from 0.21703\n","Epoch 9/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2205 - accuracy: 0.6465 - precision_8: 0.5561 - recall_8: 0.6921 - val_loss: 0.2122 - val_accuracy: 0.6715 - val_precision_8: 0.5899 - val_recall_8: 0.6486\n","\n","Epoch 00009: val_loss improved from 0.21703 to 0.21223, saving model to Test1.h5\n","Epoch 10/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2164 - accuracy: 0.6556 - precision_8: 0.5654 - recall_8: 0.6960 - val_loss: 0.2126 - val_accuracy: 0.6705 - val_precision_8: 0.5814 - val_recall_8: 0.6970\n","\n","Epoch 00010: val_loss did not improve from 0.21223\n","Epoch 11/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2156 - accuracy: 0.6551 - precision_8: 0.5655 - recall_8: 0.6996 - val_loss: 0.2086 - val_accuracy: 0.6788 - val_precision_8: 0.5974 - val_recall_8: 0.6607\n","\n","Epoch 00011: val_loss improved from 0.21223 to 0.20863, saving model to Test1.h5\n","Epoch 12/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.6652 - precision_8: 0.5751 - recall_8: 0.6984 - val_loss: 0.2103 - val_accuracy: 0.6747 - val_precision_8: 0.5844 - val_recall_8: 0.7120\n","\n","Epoch 00012: val_loss did not improve from 0.20863\n","Epoch 13/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2144 - accuracy: 0.6587 - precision_8: 0.5709 - recall_8: 0.6999 - val_loss: 0.2107 - val_accuracy: 0.6729 - val_precision_8: 0.5793 - val_recall_8: 0.7346\n","\n","Epoch 00013: val_loss did not improve from 0.20863\n","Epoch 14/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2110 - accuracy: 0.6630 - precision_8: 0.5757 - recall_8: 0.7126 - val_loss: 0.2082 - val_accuracy: 0.6766 - val_precision_8: 0.5850 - val_recall_8: 0.7231\n","\n","Epoch 00014: val_loss improved from 0.20863 to 0.20823, saving model to Test1.h5\n","Epoch 15/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2110 - accuracy: 0.6679 - precision_8: 0.5770 - recall_8: 0.7038 - val_loss: 0.2121 - val_accuracy: 0.6715 - val_precision_8: 0.5737 - val_recall_8: 0.7695\n","\n","Epoch 00015: val_loss did not improve from 0.20823\n","Epoch 16/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2083 - accuracy: 0.6710 - precision_8: 0.5779 - recall_8: 0.7198 - val_loss: 0.2025 - val_accuracy: 0.6889 - val_precision_8: 0.6114 - val_recall_8: 0.6594\n","\n","Epoch 00016: val_loss improved from 0.20823 to 0.20248, saving model to Test1.h5\n","Epoch 17/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2091 - accuracy: 0.6710 - precision_8: 0.5813 - recall_8: 0.7036 - val_loss: 0.2056 - val_accuracy: 0.6868 - val_precision_8: 0.5966 - val_recall_8: 0.7261\n","\n","Epoch 00017: val_loss did not improve from 0.20248\n","Epoch 18/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2090 - accuracy: 0.6679 - precision_8: 0.5806 - recall_8: 0.7160 - val_loss: 0.2056 - val_accuracy: 0.6842 - val_precision_8: 0.5919 - val_recall_8: 0.7372\n","\n","Epoch 00018: val_loss did not improve from 0.20248\n","Epoch 19/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2071 - accuracy: 0.6705 - precision_8: 0.5860 - recall_8: 0.7282 - val_loss: 0.2073 - val_accuracy: 0.6802 - val_precision_8: 0.5841 - val_recall_8: 0.7607\n","\n","Epoch 00019: val_loss did not improve from 0.20248\n","Epoch 20/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2068 - accuracy: 0.6697 - precision_8: 0.5821 - recall_8: 0.7262 - val_loss: 0.2015 - val_accuracy: 0.6947 - val_precision_8: 0.6096 - val_recall_8: 0.7071\n","\n","Epoch 00020: val_loss improved from 0.20248 to 0.20145, saving model to Test1.h5\n","Epoch 21/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2053 - accuracy: 0.6754 - precision_8: 0.5868 - recall_8: 0.7164 - val_loss: 0.2057 - val_accuracy: 0.6830 - val_precision_8: 0.5866 - val_recall_8: 0.7650\n","\n","Epoch 00021: val_loss did not improve from 0.20145\n","Epoch 22/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2057 - accuracy: 0.6750 - precision_8: 0.5855 - recall_8: 0.7193 - val_loss: 0.1996 - val_accuracy: 0.6942 - val_precision_8: 0.6128 - val_recall_8: 0.6875\n","\n","Epoch 00022: val_loss improved from 0.20145 to 0.19956, saving model to Test1.h5\n","Epoch 23/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2035 - accuracy: 0.6817 - precision_8: 0.5947 - recall_8: 0.7286 - val_loss: 0.2001 - val_accuracy: 0.6951 - val_precision_8: 0.6105 - val_recall_8: 0.7055\n","\n","Epoch 00023: val_loss did not improve from 0.19956\n","Epoch 24/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2063 - accuracy: 0.6804 - precision_8: 0.5956 - recall_8: 0.7303 - val_loss: 0.2056 - val_accuracy: 0.6821 - val_precision_8: 0.5841 - val_recall_8: 0.7767\n","\n","Epoch 00024: val_loss did not improve from 0.19956\n","Epoch 25/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2051 - accuracy: 0.6764 - precision_8: 0.5838 - recall_8: 0.7197 - val_loss: 0.2036 - val_accuracy: 0.6881 - val_precision_8: 0.5927 - val_recall_8: 0.7620\n","\n","Epoch 00025: val_loss did not improve from 0.19956\n","Epoch 26/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2045 - accuracy: 0.6804 - precision_8: 0.5873 - recall_8: 0.7255 - val_loss: 0.2053 - val_accuracy: 0.6804 - val_precision_8: 0.5821 - val_recall_8: 0.7774\n","\n","Epoch 00026: val_loss did not improve from 0.19956\n","Epoch 27/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2043 - accuracy: 0.6775 - precision_8: 0.5894 - recall_8: 0.7327 - val_loss: 0.1972 - val_accuracy: 0.7026 - val_precision_8: 0.6259 - val_recall_8: 0.6800\n","\n","Epoch 00027: val_loss improved from 0.19956 to 0.19721, saving model to Test1.h5\n","Epoch 28/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2020 - accuracy: 0.6854 - precision_8: 0.5961 - recall_8: 0.7267 - val_loss: 0.2000 - val_accuracy: 0.6942 - val_precision_8: 0.6028 - val_recall_8: 0.7417\n","\n","Epoch 00028: val_loss did not improve from 0.19721\n","Epoch 29/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2023 - accuracy: 0.6802 - precision_8: 0.5876 - recall_8: 0.7238 - val_loss: 0.2038 - val_accuracy: 0.6836 - val_precision_8: 0.5855 - val_recall_8: 0.7780\n","\n","Epoch 00029: val_loss did not improve from 0.19721\n","Epoch 30/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2033 - accuracy: 0.6802 - precision_8: 0.5891 - recall_8: 0.7264 - val_loss: 0.1991 - val_accuracy: 0.6951 - val_precision_8: 0.6046 - val_recall_8: 0.7381\n","\n","Epoch 00030: val_loss did not improve from 0.19721\n","Epoch 31/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2034 - accuracy: 0.6798 - precision_8: 0.5881 - recall_8: 0.7253 - val_loss: 0.1970 - val_accuracy: 0.7016 - val_precision_8: 0.6176 - val_recall_8: 0.7123\n","\n","Epoch 00031: val_loss improved from 0.19721 to 0.19699, saving model to Test1.h5\n","Epoch 32/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2032 - accuracy: 0.6801 - precision_8: 0.5899 - recall_8: 0.7154 - val_loss: 0.1962 - val_accuracy: 0.7034 - val_precision_8: 0.6219 - val_recall_8: 0.7028\n","\n","Epoch 00032: val_loss improved from 0.19699 to 0.19624, saving model to Test1.h5\n","Epoch 33/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2024 - accuracy: 0.6838 - precision_8: 0.5954 - recall_8: 0.7232 - val_loss: 0.1962 - val_accuracy: 0.7022 - val_precision_8: 0.6202 - val_recall_8: 0.7032\n","\n","Epoch 00033: val_loss improved from 0.19624 to 0.19616, saving model to Test1.h5\n","Epoch 34/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.6846 - precision_8: 0.5946 - recall_8: 0.7260 - val_loss: 0.2005 - val_accuracy: 0.6875 - val_precision_8: 0.5919 - val_recall_8: 0.7623\n","\n","Epoch 00034: val_loss did not improve from 0.19616\n","Epoch 35/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2010 - accuracy: 0.6829 - precision_8: 0.5906 - recall_8: 0.7256 - val_loss: 0.2011 - val_accuracy: 0.6881 - val_precision_8: 0.5912 - val_recall_8: 0.7725\n","\n","Epoch 00035: val_loss did not improve from 0.19616\n","Epoch 36/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2025 - accuracy: 0.6822 - precision_8: 0.5912 - recall_8: 0.7268 - val_loss: 0.1989 - val_accuracy: 0.6948 - val_precision_8: 0.6023 - val_recall_8: 0.7499\n","\n","Epoch 00036: val_loss did not improve from 0.19616\n","Epoch 37/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.2009 - accuracy: 0.6835 - precision_8: 0.5959 - recall_8: 0.7330 - val_loss: 0.1963 - val_accuracy: 0.7023 - val_precision_8: 0.6161 - val_recall_8: 0.7241\n","\n","Epoch 00037: val_loss did not improve from 0.19616\n","Epoch 38/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.6813 - precision_8: 0.5917 - recall_8: 0.7240 - val_loss: 0.2011 - val_accuracy: 0.6845 - val_precision_8: 0.5870 - val_recall_8: 0.7741\n","\n","Epoch 00038: val_loss did not improve from 0.19616\n","Epoch 39/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1999 - accuracy: 0.6854 - precision_8: 0.5975 - recall_8: 0.7353 - val_loss: 0.1974 - val_accuracy: 0.6958 - val_precision_8: 0.6031 - val_recall_8: 0.7512\n","\n","Epoch 00039: val_loss did not improve from 0.19616\n","Epoch 40/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1983 - accuracy: 0.6917 - precision_8: 0.6039 - recall_8: 0.7436 - val_loss: 0.1956 - val_accuracy: 0.7018 - val_precision_8: 0.6150 - val_recall_8: 0.7264\n","\n","Epoch 00040: val_loss improved from 0.19616 to 0.19557, saving model to Test1.h5\n","Epoch 41/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2018 - accuracy: 0.6786 - precision_8: 0.5850 - recall_8: 0.7246 - val_loss: 0.2015 - val_accuracy: 0.6855 - val_precision_8: 0.5870 - val_recall_8: 0.7816\n","\n","Epoch 00041: val_loss did not improve from 0.19557\n","Epoch 42/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1993 - accuracy: 0.6861 - precision_8: 0.5940 - recall_8: 0.7401 - val_loss: 0.1939 - val_accuracy: 0.7026 - val_precision_8: 0.6216 - val_recall_8: 0.6992\n","\n","Epoch 00042: val_loss improved from 0.19557 to 0.19394, saving model to Test1.h5\n","Epoch 43/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.6819 - precision_8: 0.5945 - recall_8: 0.7312 - val_loss: 0.2050 - val_accuracy: 0.6797 - val_precision_8: 0.5779 - val_recall_8: 0.8071\n","\n","Epoch 00043: val_loss did not improve from 0.19394\n","Epoch 44/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.2007 - accuracy: 0.6836 - precision_8: 0.5955 - recall_8: 0.7355 - val_loss: 0.1964 - val_accuracy: 0.6988 - val_precision_8: 0.6072 - val_recall_8: 0.7493\n","\n","Epoch 00044: val_loss did not improve from 0.19394\n","Epoch 45/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1992 - accuracy: 0.6861 - precision_8: 0.5976 - recall_8: 0.7345 - val_loss: 0.1931 - val_accuracy: 0.7067 - val_precision_8: 0.6286 - val_recall_8: 0.6934\n","\n","Epoch 00045: val_loss improved from 0.19394 to 0.19312, saving model to Test1.h5\n","Epoch 46/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1991 - accuracy: 0.6863 - precision_8: 0.5968 - recall_8: 0.7390 - val_loss: 0.1942 - val_accuracy: 0.7046 - val_precision_8: 0.6201 - val_recall_8: 0.7192\n","\n","Epoch 00046: val_loss did not improve from 0.19312\n","Epoch 47/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1996 - accuracy: 0.6883 - precision_8: 0.5996 - recall_8: 0.7301 - val_loss: 0.1949 - val_accuracy: 0.7022 - val_precision_8: 0.6137 - val_recall_8: 0.7355\n","\n","Epoch 00047: val_loss did not improve from 0.19312\n","Epoch 48/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1986 - accuracy: 0.6874 - precision_8: 0.5982 - recall_8: 0.7359 - val_loss: 0.2006 - val_accuracy: 0.6900 - val_precision_8: 0.5917 - val_recall_8: 0.7839\n","\n","Epoch 00048: val_loss did not improve from 0.19312\n","Epoch 49/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.6915 - precision_8: 0.6027 - recall_8: 0.7426 - val_loss: 0.1972 - val_accuracy: 0.6966 - val_precision_8: 0.6023 - val_recall_8: 0.7623\n","\n","Epoch 00049: val_loss did not improve from 0.19312\n","Epoch 50/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1999 - accuracy: 0.6832 - precision_8: 0.5955 - recall_8: 0.7376 - val_loss: 0.1992 - val_accuracy: 0.6897 - val_precision_8: 0.5920 - val_recall_8: 0.7790\n","\n","Epoch 00050: val_loss did not improve from 0.19312\n","Epoch 51/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1988 - accuracy: 0.6863 - precision_8: 0.5950 - recall_8: 0.7464 - val_loss: 0.1979 - val_accuracy: 0.6927 - val_precision_8: 0.5966 - val_recall_8: 0.7705\n","\n","Epoch 00051: val_loss did not improve from 0.19312\n","Epoch 52/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1992 - accuracy: 0.6857 - precision_8: 0.5919 - recall_8: 0.7306 - val_loss: 0.1948 - val_accuracy: 0.7027 - val_precision_8: 0.6125 - val_recall_8: 0.7457\n","\n","Epoch 00052: val_loss did not improve from 0.19312\n","Epoch 53/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1998 - accuracy: 0.6852 - precision_8: 0.6000 - recall_8: 0.7314 - val_loss: 0.1956 - val_accuracy: 0.6987 - val_precision_8: 0.6060 - val_recall_8: 0.7548\n","\n","Epoch 00053: val_loss did not improve from 0.19312\n","Epoch 54/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1990 - accuracy: 0.6881 - precision_8: 0.6016 - recall_8: 0.7317 - val_loss: 0.1972 - val_accuracy: 0.6939 - val_precision_8: 0.5982 - val_recall_8: 0.7686\n","\n","Epoch 00054: val_loss did not improve from 0.19312\n","Epoch 55/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1991 - accuracy: 0.6838 - precision_8: 0.5937 - recall_8: 0.7392 - val_loss: 0.1947 - val_accuracy: 0.7011 - val_precision_8: 0.6109 - val_recall_8: 0.7437\n","\n","Epoch 00055: val_loss did not improve from 0.19312\n","Epoch 56/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1988 - accuracy: 0.6887 - precision_8: 0.6032 - recall_8: 0.7353 - val_loss: 0.2037 - val_accuracy: 0.6834 - val_precision_8: 0.5813 - val_recall_8: 0.8114\n","\n","Epoch 00056: val_loss did not improve from 0.19312\n","Epoch 57/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.6899 - precision_8: 0.5998 - recall_8: 0.7377 - val_loss: 0.1960 - val_accuracy: 0.6975 - val_precision_8: 0.6034 - val_recall_8: 0.7620\n","\n","Epoch 00057: val_loss did not improve from 0.19312\n","Epoch 58/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1981 - accuracy: 0.6890 - precision_8: 0.5966 - recall_8: 0.7368 - val_loss: 0.1927 - val_accuracy: 0.7047 - val_precision_8: 0.6209 - val_recall_8: 0.7159\n","\n","Epoch 00058: val_loss improved from 0.19312 to 0.19270, saving model to Test1.h5\n","Epoch 59/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1991 - accuracy: 0.6867 - precision_8: 0.6006 - recall_8: 0.7390 - val_loss: 0.1940 - val_accuracy: 0.7012 - val_precision_8: 0.6118 - val_recall_8: 0.7398\n","\n","Epoch 00059: val_loss did not improve from 0.19270\n","Epoch 60/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1962 - accuracy: 0.6914 - precision_8: 0.6022 - recall_8: 0.7397 - val_loss: 0.1962 - val_accuracy: 0.6956 - val_precision_8: 0.6012 - val_recall_8: 0.7620\n","\n","Epoch 00060: val_loss did not improve from 0.19270\n","Epoch 61/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1981 - accuracy: 0.6899 - precision_8: 0.5988 - recall_8: 0.7366 - val_loss: 0.1934 - val_accuracy: 0.7053 - val_precision_8: 0.6178 - val_recall_8: 0.7346\n","\n","Epoch 00061: val_loss did not improve from 0.19270\n","Epoch 62/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1975 - accuracy: 0.6895 - precision_8: 0.6007 - recall_8: 0.7403 - val_loss: 0.1969 - val_accuracy: 0.6919 - val_precision_8: 0.5960 - val_recall_8: 0.7682\n","\n","Epoch 00062: val_loss did not improve from 0.19270\n","Epoch 63/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1983 - accuracy: 0.6876 - precision_8: 0.5951 - recall_8: 0.7313 - val_loss: 0.1934 - val_accuracy: 0.7046 - val_precision_8: 0.6158 - val_recall_8: 0.7408\n","\n","Epoch 00063: val_loss did not improve from 0.19270\n","Epoch 64/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1998 - accuracy: 0.6822 - precision_8: 0.5926 - recall_8: 0.7339 - val_loss: 0.1983 - val_accuracy: 0.6912 - val_precision_8: 0.5931 - val_recall_8: 0.7829\n","\n","Epoch 00064: val_loss did not improve from 0.19270\n","Epoch 65/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1973 - accuracy: 0.6895 - precision_8: 0.5989 - recall_8: 0.7341 - val_loss: 0.1925 - val_accuracy: 0.7067 - val_precision_8: 0.6216 - val_recall_8: 0.7251\n","\n","Epoch 00065: val_loss improved from 0.19270 to 0.19248, saving model to Test1.h5\n","Epoch 66/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1969 - accuracy: 0.6908 - precision_8: 0.6001 - recall_8: 0.7304 - val_loss: 0.1941 - val_accuracy: 0.7020 - val_precision_8: 0.6108 - val_recall_8: 0.7506\n","\n","Epoch 00066: val_loss did not improve from 0.19248\n","Epoch 67/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1976 - accuracy: 0.6884 - precision_8: 0.6009 - recall_8: 0.7394 - val_loss: 0.1943 - val_accuracy: 0.7014 - val_precision_8: 0.6100 - val_recall_8: 0.7506\n","\n","Epoch 00067: val_loss did not improve from 0.19248\n","Epoch 68/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.6931 - precision_8: 0.6048 - recall_8: 0.7453 - val_loss: 0.1923 - val_accuracy: 0.7065 - val_precision_8: 0.6201 - val_recall_8: 0.7310\n","\n","Epoch 00068: val_loss improved from 0.19248 to 0.19229, saving model to Test1.h5\n","Epoch 69/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1977 - accuracy: 0.6900 - precision_8: 0.5991 - recall_8: 0.7260 - val_loss: 0.1913 - val_accuracy: 0.7085 - val_precision_8: 0.6263 - val_recall_8: 0.7140\n","\n","Epoch 00069: val_loss improved from 0.19229 to 0.19134, saving model to Test1.h5\n","Epoch 70/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1959 - accuracy: 0.6932 - precision_8: 0.6055 - recall_8: 0.7391 - val_loss: 0.1928 - val_accuracy: 0.7050 - val_precision_8: 0.6169 - val_recall_8: 0.7375\n","\n","Epoch 00070: val_loss did not improve from 0.19134\n","Epoch 71/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1950 - accuracy: 0.6958 - precision_8: 0.6094 - recall_8: 0.7429 - val_loss: 0.1916 - val_accuracy: 0.7083 - val_precision_8: 0.6248 - val_recall_8: 0.7202\n","\n","Epoch 00071: val_loss did not improve from 0.19134\n","Epoch 72/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1961 - accuracy: 0.6923 - precision_8: 0.6051 - recall_8: 0.7345 - val_loss: 0.1930 - val_accuracy: 0.7046 - val_precision_8: 0.6158 - val_recall_8: 0.7408\n","\n","Epoch 00072: val_loss did not improve from 0.19134\n","Epoch 73/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1954 - accuracy: 0.6936 - precision_8: 0.6046 - recall_8: 0.7422 - val_loss: 0.1966 - val_accuracy: 0.6944 - val_precision_8: 0.5974 - val_recall_8: 0.7780\n","\n","Epoch 00073: val_loss did not improve from 0.19134\n","Epoch 74/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1961 - accuracy: 0.6923 - precision_8: 0.6038 - recall_8: 0.7411 - val_loss: 0.1966 - val_accuracy: 0.6956 - val_precision_8: 0.5990 - val_recall_8: 0.7761\n","\n","Epoch 00074: val_loss did not improve from 0.19134\n","Epoch 75/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1967 - accuracy: 0.6897 - precision_8: 0.5986 - recall_8: 0.7404 - val_loss: 0.1956 - val_accuracy: 0.6984 - val_precision_8: 0.6037 - val_recall_8: 0.7672\n","\n","Epoch 00075: val_loss did not improve from 0.19134\n","Epoch 76/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1969 - accuracy: 0.6932 - precision_8: 0.6019 - recall_8: 0.7360 - val_loss: 0.1985 - val_accuracy: 0.6887 - val_precision_8: 0.5895 - val_recall_8: 0.7891\n","\n","Epoch 00076: val_loss did not improve from 0.19134\n","Epoch 77/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.6934 - precision_8: 0.6010 - recall_8: 0.7398 - val_loss: 0.1942 - val_accuracy: 0.7003 - val_precision_8: 0.6078 - val_recall_8: 0.7558\n","\n","Epoch 00077: val_loss did not improve from 0.19134\n","Epoch 78/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1949 - accuracy: 0.6960 - precision_8: 0.6080 - recall_8: 0.7465 - val_loss: 0.1964 - val_accuracy: 0.6967 - val_precision_8: 0.6007 - val_recall_8: 0.7731\n","\n","Epoch 00078: val_loss did not improve from 0.19134\n","Epoch 79/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1976 - accuracy: 0.6885 - precision_8: 0.6005 - recall_8: 0.7329 - val_loss: 0.1910 - val_accuracy: 0.7098 - val_precision_8: 0.6281 - val_recall_8: 0.7143\n","\n","Epoch 00079: val_loss improved from 0.19134 to 0.19104, saving model to Test1.h5\n","Epoch 80/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.6942 - precision_8: 0.6061 - recall_8: 0.7285 - val_loss: 0.2013 - val_accuracy: 0.6859 - val_precision_8: 0.5842 - val_recall_8: 0.8078\n","\n","Epoch 00080: val_loss did not improve from 0.19104\n","Epoch 81/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1950 - accuracy: 0.6952 - precision_8: 0.6028 - recall_8: 0.7327 - val_loss: 0.1975 - val_accuracy: 0.6942 - val_precision_8: 0.5964 - val_recall_8: 0.7829\n","\n","Epoch 00081: val_loss did not improve from 0.19104\n","Epoch 82/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1950 - accuracy: 0.6946 - precision_8: 0.6048 - recall_8: 0.7475 - val_loss: 0.1966 - val_accuracy: 0.6970 - val_precision_8: 0.6011 - val_recall_8: 0.7728\n","\n","Epoch 00082: val_loss did not improve from 0.19104\n","Epoch 83/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1968 - accuracy: 0.6896 - precision_8: 0.5983 - recall_8: 0.7316 - val_loss: 0.1917 - val_accuracy: 0.7057 - val_precision_8: 0.6203 - val_recall_8: 0.7247\n","\n","Epoch 00083: val_loss did not improve from 0.19104\n","Epoch 84/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.6918 - precision_8: 0.6020 - recall_8: 0.7327 - val_loss: 0.1980 - val_accuracy: 0.6919 - val_precision_8: 0.5931 - val_recall_8: 0.7885\n","\n","Epoch 00084: val_loss did not improve from 0.19104\n","Epoch 85/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1957 - accuracy: 0.6936 - precision_8: 0.6051 - recall_8: 0.7378 - val_loss: 0.1945 - val_accuracy: 0.7008 - val_precision_8: 0.6073 - val_recall_8: 0.7623\n","\n","Epoch 00085: val_loss did not improve from 0.19104\n","Epoch 86/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1965 - accuracy: 0.6913 - precision_8: 0.6014 - recall_8: 0.7285 - val_loss: 0.1920 - val_accuracy: 0.7067 - val_precision_8: 0.6198 - val_recall_8: 0.7342\n","\n","Epoch 00086: val_loss did not improve from 0.19104\n","Epoch 87/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1968 - accuracy: 0.6882 - precision_8: 0.5979 - recall_8: 0.7368 - val_loss: 0.1908 - val_accuracy: 0.7082 - val_precision_8: 0.6250 - val_recall_8: 0.7182\n","\n","Epoch 00087: val_loss improved from 0.19104 to 0.19085, saving model to Test1.h5\n","Epoch 88/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1967 - accuracy: 0.6902 - precision_8: 0.6027 - recall_8: 0.7431 - val_loss: 0.1897 - val_accuracy: 0.7101 - val_precision_8: 0.6373 - val_recall_8: 0.6777\n","\n","Epoch 00088: val_loss improved from 0.19085 to 0.18966, saving model to Test1.h5\n","Epoch 89/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1976 - accuracy: 0.6890 - precision_8: 0.6016 - recall_8: 0.7327 - val_loss: 0.1976 - val_accuracy: 0.6944 - val_precision_8: 0.5962 - val_recall_8: 0.7862\n","\n","Epoch 00089: val_loss did not improve from 0.18966\n","Epoch 90/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1945 - accuracy: 0.6943 - precision_8: 0.6067 - recall_8: 0.7458 - val_loss: 0.1972 - val_accuracy: 0.6933 - val_precision_8: 0.5954 - val_recall_8: 0.7836\n","\n","Epoch 00090: val_loss did not improve from 0.18966\n","Epoch 91/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1967 - accuracy: 0.6876 - precision_8: 0.5976 - recall_8: 0.7321 - val_loss: 0.1911 - val_accuracy: 0.7074 - val_precision_8: 0.6226 - val_recall_8: 0.7244\n","\n","Epoch 00091: val_loss did not improve from 0.18966\n","Epoch 92/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1960 - accuracy: 0.6942 - precision_8: 0.6040 - recall_8: 0.7313 - val_loss: 0.1963 - val_accuracy: 0.6971 - val_precision_8: 0.6001 - val_recall_8: 0.7803\n","\n","Epoch 00092: val_loss did not improve from 0.18966\n","Epoch 93/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1952 - accuracy: 0.6931 - precision_8: 0.6033 - recall_8: 0.7360 - val_loss: 0.1895 - val_accuracy: 0.7097 - val_precision_8: 0.6313 - val_recall_8: 0.6996\n","\n","Epoch 00093: val_loss improved from 0.18966 to 0.18950, saving model to Test1.h5\n","Epoch 94/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1970 - accuracy: 0.6919 - precision_8: 0.6045 - recall_8: 0.7325 - val_loss: 0.1932 - val_accuracy: 0.7023 - val_precision_8: 0.6116 - val_recall_8: 0.7480\n","\n","Epoch 00094: val_loss did not improve from 0.18950\n","Epoch 95/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1948 - accuracy: 0.6954 - precision_8: 0.6061 - recall_8: 0.7351 - val_loss: 0.1906 - val_accuracy: 0.7091 - val_precision_8: 0.6304 - val_recall_8: 0.7002\n","\n","Epoch 00095: val_loss did not improve from 0.18950\n","Epoch 96/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1985 - accuracy: 0.6903 - precision_8: 0.6020 - recall_8: 0.7253 - val_loss: 0.1929 - val_accuracy: 0.7020 - val_precision_8: 0.6105 - val_recall_8: 0.7522\n","\n","Epoch 00096: val_loss did not improve from 0.18950\n","Epoch 97/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1978 - accuracy: 0.6927 - precision_8: 0.6083 - recall_8: 0.7353 - val_loss: 0.1923 - val_accuracy: 0.7061 - val_precision_8: 0.6176 - val_recall_8: 0.7408\n","\n","Epoch 00097: val_loss did not improve from 0.18950\n","Epoch 98/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.6929 - precision_8: 0.6015 - recall_8: 0.7283 - val_loss: 0.1917 - val_accuracy: 0.7075 - val_precision_8: 0.6211 - val_recall_8: 0.7329\n","\n","Epoch 00098: val_loss did not improve from 0.18950\n","Epoch 99/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1939 - accuracy: 0.6981 - precision_8: 0.6096 - recall_8: 0.7416 - val_loss: 0.1929 - val_accuracy: 0.7042 - val_precision_8: 0.6144 - val_recall_8: 0.7453\n","\n","Epoch 00099: val_loss did not improve from 0.18950\n","Epoch 100/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1935 - accuracy: 0.6969 - precision_8: 0.6073 - recall_8: 0.7435 - val_loss: 0.1960 - val_accuracy: 0.6960 - val_precision_8: 0.5991 - val_recall_8: 0.7787\n","\n","Epoch 00100: val_loss did not improve from 0.18950\n","Epoch 101/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1936 - accuracy: 0.6977 - precision_8: 0.6083 - recall_8: 0.7464 - val_loss: 0.1932 - val_accuracy: 0.7035 - val_precision_8: 0.6114 - val_recall_8: 0.7571\n","\n","Epoch 00101: val_loss did not improve from 0.18950\n","Epoch 102/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1954 - accuracy: 0.6923 - precision_8: 0.6041 - recall_8: 0.7363 - val_loss: 0.1955 - val_accuracy: 0.6995 - val_precision_8: 0.6034 - val_recall_8: 0.7767\n","\n","Epoch 00102: val_loss did not improve from 0.18950\n","Epoch 103/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1939 - accuracy: 0.6953 - precision_8: 0.6004 - recall_8: 0.7437 - val_loss: 0.1947 - val_accuracy: 0.6962 - val_precision_8: 0.6012 - val_recall_8: 0.7663\n","\n","Epoch 00103: val_loss did not improve from 0.18950\n","Epoch 104/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.6979 - precision_8: 0.6085 - recall_8: 0.7379 - val_loss: 0.1919 - val_accuracy: 0.7045 - val_precision_8: 0.6148 - val_recall_8: 0.7450\n","\n","Epoch 00104: val_loss did not improve from 0.18950\n","Epoch 105/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1928 - accuracy: 0.7024 - precision_8: 0.6146 - recall_8: 0.7359 - val_loss: 0.1952 - val_accuracy: 0.7003 - val_precision_8: 0.6044 - val_recall_8: 0.7761\n","\n","Epoch 00105: val_loss did not improve from 0.18950\n","Epoch 106/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1953 - accuracy: 0.6973 - precision_8: 0.6080 - recall_8: 0.7402 - val_loss: 0.1995 - val_accuracy: 0.6936 - val_precision_8: 0.5928 - val_recall_8: 0.8039\n","\n","Epoch 00106: val_loss did not improve from 0.18950\n","Epoch 107/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1942 - accuracy: 0.6926 - precision_8: 0.5974 - recall_8: 0.7405 - val_loss: 0.1943 - val_accuracy: 0.7007 - val_precision_8: 0.6065 - val_recall_8: 0.7659\n","\n","Epoch 00107: val_loss did not improve from 0.18950\n","Epoch 108/150\n","598/598 [==============================] - 1s 3ms/step - loss: 0.1946 - accuracy: 0.6966 - precision_8: 0.6070 - recall_8: 0.7361 - val_loss: 0.1931 - val_accuracy: 0.7041 - val_precision_8: 0.6119 - val_recall_8: 0.7581\n","\n","Epoch 00108: val_loss did not improve from 0.18950\n","Epoch 109/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1934 - accuracy: 0.6969 - precision_8: 0.6071 - recall_8: 0.7308 - val_loss: 0.1952 - val_accuracy: 0.6979 - val_precision_8: 0.6021 - val_recall_8: 0.7731\n","\n","Epoch 00109: val_loss did not improve from 0.18950\n","Epoch 110/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1950 - accuracy: 0.6971 - precision_8: 0.6044 - recall_8: 0.7439 - val_loss: 0.1958 - val_accuracy: 0.6970 - val_precision_8: 0.5995 - val_recall_8: 0.7829\n","\n","Epoch 00110: val_loss did not improve from 0.18950\n","Epoch 111/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1966 - accuracy: 0.6925 - precision_8: 0.6024 - recall_8: 0.7418 - val_loss: 0.1900 - val_accuracy: 0.7101 - val_precision_8: 0.6270 - val_recall_8: 0.7205\n","\n","Epoch 00111: val_loss did not improve from 0.18950\n","Epoch 112/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1948 - accuracy: 0.6959 - precision_8: 0.6068 - recall_8: 0.7327 - val_loss: 0.1894 - val_accuracy: 0.7110 - val_precision_8: 0.6314 - val_recall_8: 0.7068\n","\n","Epoch 00112: val_loss improved from 0.18950 to 0.18942, saving model to Test1.h5\n","Epoch 113/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1931 - accuracy: 0.7025 - precision_8: 0.6144 - recall_8: 0.7425 - val_loss: 0.1952 - val_accuracy: 0.6994 - val_precision_8: 0.6028 - val_recall_8: 0.7790\n","\n","Epoch 00113: val_loss did not improve from 0.18942\n","Epoch 114/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1950 - accuracy: 0.6937 - precision_8: 0.6041 - recall_8: 0.7325 - val_loss: 0.1900 - val_accuracy: 0.7085 - val_precision_8: 0.6257 - val_recall_8: 0.7169\n","\n","Epoch 00114: val_loss did not improve from 0.18942\n","Epoch 115/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1946 - accuracy: 0.6960 - precision_8: 0.6047 - recall_8: 0.7292 - val_loss: 0.1929 - val_accuracy: 0.7004 - val_precision_8: 0.6087 - val_recall_8: 0.7516\n","\n","Epoch 00115: val_loss did not improve from 0.18942\n","Epoch 116/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1970 - accuracy: 0.6912 - precision_8: 0.6018 - recall_8: 0.7334 - val_loss: 0.1944 - val_accuracy: 0.6984 - val_precision_8: 0.6029 - val_recall_8: 0.7718\n","\n","Epoch 00116: val_loss did not improve from 0.18942\n","Epoch 117/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1944 - accuracy: 0.6946 - precision_8: 0.6026 - recall_8: 0.7354 - val_loss: 0.1958 - val_accuracy: 0.6959 - val_precision_8: 0.5988 - val_recall_8: 0.7797\n","\n","Epoch 00117: val_loss did not improve from 0.18942\n","Epoch 118/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1945 - accuracy: 0.6963 - precision_8: 0.6065 - recall_8: 0.7324 - val_loss: 0.1942 - val_accuracy: 0.6982 - val_precision_8: 0.6040 - val_recall_8: 0.7630\n","\n","Epoch 00118: val_loss did not improve from 0.18942\n","Epoch 119/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1932 - accuracy: 0.6993 - precision_8: 0.6108 - recall_8: 0.7332 - val_loss: 0.1956 - val_accuracy: 0.6983 - val_precision_8: 0.6013 - val_recall_8: 0.7813\n","\n","Epoch 00119: val_loss did not improve from 0.18942\n","Epoch 120/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1959 - accuracy: 0.6936 - precision_8: 0.6058 - recall_8: 0.7360 - val_loss: 0.1897 - val_accuracy: 0.7078 - val_precision_8: 0.6256 - val_recall_8: 0.7130\n","\n","Epoch 00120: val_loss did not improve from 0.18942\n","Epoch 121/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1942 - accuracy: 0.6962 - precision_8: 0.6059 - recall_8: 0.7356 - val_loss: 0.1936 - val_accuracy: 0.7007 - val_precision_8: 0.6067 - val_recall_8: 0.7650\n","\n","Epoch 00121: val_loss did not improve from 0.18942\n","Epoch 122/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1944 - accuracy: 0.7019 - precision_8: 0.6129 - recall_8: 0.7404 - val_loss: 0.1958 - val_accuracy: 0.6959 - val_precision_8: 0.5983 - val_recall_8: 0.7829\n","\n","Epoch 00122: val_loss did not improve from 0.18942\n","Epoch 123/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1936 - accuracy: 0.6976 - precision_8: 0.6088 - recall_8: 0.7447 - val_loss: 0.1909 - val_accuracy: 0.7078 - val_precision_8: 0.6196 - val_recall_8: 0.7417\n","\n","Epoch 00123: val_loss did not improve from 0.18942\n","Epoch 124/150\n","598/598 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.6930 - precision_8: 0.6040 - recall_8: 0.7396 - val_loss: 0.1916 - val_accuracy: 0.7086 - val_precision_8: 0.6188 - val_recall_8: 0.7509\n","\n","Epoch 00124: val_loss did not improve from 0.18942\n","Epoch 125/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1958 - accuracy: 0.6951 - precision_8: 0.6070 - recall_8: 0.7353 - val_loss: 0.1896 - val_accuracy: 0.7095 - val_precision_8: 0.6285 - val_recall_8: 0.7107\n","\n","Epoch 00125: val_loss did not improve from 0.18942\n","Epoch 126/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1934 - accuracy: 0.6949 - precision_8: 0.6035 - recall_8: 0.7349 - val_loss: 0.1910 - val_accuracy: 0.7057 - val_precision_8: 0.6174 - val_recall_8: 0.7395\n","\n","Epoch 00126: val_loss did not improve from 0.18942\n","Epoch 127/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1929 - accuracy: 0.6988 - precision_8: 0.6091 - recall_8: 0.7410 - val_loss: 0.1989 - val_accuracy: 0.6884 - val_precision_8: 0.5876 - val_recall_8: 0.8016\n","\n","Epoch 00127: val_loss did not improve from 0.18942\n","Epoch 128/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1943 - accuracy: 0.6964 - precision_8: 0.6121 - recall_8: 0.7524 - val_loss: 0.1899 - val_accuracy: 0.7077 - val_precision_8: 0.6231 - val_recall_8: 0.7241\n","\n","Epoch 00128: val_loss did not improve from 0.18942\n","Epoch 129/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1941 - accuracy: 0.6955 - precision_8: 0.6062 - recall_8: 0.7361 - val_loss: 0.1910 - val_accuracy: 0.7083 - val_precision_8: 0.6205 - val_recall_8: 0.7404\n","\n","Epoch 00129: val_loss did not improve from 0.18942\n","Epoch 130/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1944 - accuracy: 0.6957 - precision_8: 0.6108 - recall_8: 0.7426 - val_loss: 0.1879 - val_accuracy: 0.7117 - val_precision_8: 0.6385 - val_recall_8: 0.6819\n","\n","Epoch 00130: val_loss improved from 0.18942 to 0.18787, saving model to Test1.h5\n","Epoch 131/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1954 - accuracy: 0.6944 - precision_8: 0.6075 - recall_8: 0.7287 - val_loss: 0.1934 - val_accuracy: 0.7024 - val_precision_8: 0.6098 - val_recall_8: 0.7591\n","\n","Epoch 00131: val_loss did not improve from 0.18787\n","Epoch 132/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1952 - accuracy: 0.6953 - precision_8: 0.6057 - recall_8: 0.7356 - val_loss: 0.1950 - val_accuracy: 0.7006 - val_precision_8: 0.6048 - val_recall_8: 0.7754\n","\n","Epoch 00132: val_loss did not improve from 0.18787\n","Epoch 133/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1937 - accuracy: 0.6970 - precision_8: 0.6101 - recall_8: 0.7404 - val_loss: 0.1882 - val_accuracy: 0.7095 - val_precision_8: 0.6382 - val_recall_8: 0.6711\n","\n","Epoch 00133: val_loss did not improve from 0.18787\n","Epoch 134/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1926 - accuracy: 0.6967 - precision_8: 0.6061 - recall_8: 0.7303 - val_loss: 0.1908 - val_accuracy: 0.7071 - val_precision_8: 0.6193 - val_recall_8: 0.7391\n","\n","Epoch 00134: val_loss did not improve from 0.18787\n","Epoch 135/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1936 - accuracy: 0.6974 - precision_8: 0.6103 - recall_8: 0.7444 - val_loss: 0.1895 - val_accuracy: 0.7099 - val_precision_8: 0.6274 - val_recall_8: 0.7179\n","\n","Epoch 00135: val_loss did not improve from 0.18787\n","Epoch 136/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1972 - accuracy: 0.6932 - precision_8: 0.6073 - recall_8: 0.7331 - val_loss: 0.1953 - val_accuracy: 0.6983 - val_precision_8: 0.6010 - val_recall_8: 0.7829\n","\n","Epoch 00136: val_loss did not improve from 0.18787\n","Epoch 137/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1927 - accuracy: 0.6982 - precision_8: 0.6075 - recall_8: 0.7326 - val_loss: 0.1910 - val_accuracy: 0.7078 - val_precision_8: 0.6201 - val_recall_8: 0.7395\n","\n","Epoch 00137: val_loss did not improve from 0.18787\n","Epoch 138/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1941 - accuracy: 0.7017 - precision_8: 0.6113 - recall_8: 0.7370 - val_loss: 0.1960 - val_accuracy: 0.6975 - val_precision_8: 0.5993 - val_recall_8: 0.7885\n","\n","Epoch 00138: val_loss did not improve from 0.18787\n","Epoch 139/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1933 - accuracy: 0.6972 - precision_8: 0.6054 - recall_8: 0.7379 - val_loss: 0.1958 - val_accuracy: 0.6959 - val_precision_8: 0.5984 - val_recall_8: 0.7826\n","\n","Epoch 00139: val_loss did not improve from 0.18787\n","Epoch 140/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1939 - accuracy: 0.6978 - precision_8: 0.6068 - recall_8: 0.7390 - val_loss: 0.1954 - val_accuracy: 0.6994 - val_precision_8: 0.6022 - val_recall_8: 0.7829\n","\n","Epoch 00140: val_loss did not improve from 0.18787\n","Epoch 141/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1920 - accuracy: 0.7001 - precision_8: 0.6095 - recall_8: 0.7448 - val_loss: 0.1978 - val_accuracy: 0.6929 - val_precision_8: 0.5925 - val_recall_8: 0.8006\n","\n","Epoch 00141: val_loss did not improve from 0.18787\n","Epoch 142/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1954 - accuracy: 0.6950 - precision_8: 0.6092 - recall_8: 0.7458 - val_loss: 0.1903 - val_accuracy: 0.7067 - val_precision_8: 0.6192 - val_recall_8: 0.7372\n","\n","Epoch 00142: val_loss did not improve from 0.18787\n","Epoch 143/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1954 - accuracy: 0.6922 - precision_8: 0.5997 - recall_8: 0.7275 - val_loss: 0.1977 - val_accuracy: 0.6924 - val_precision_8: 0.5936 - val_recall_8: 0.7885\n","\n","Epoch 00143: val_loss did not improve from 0.18787\n","Epoch 144/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1929 - accuracy: 0.6978 - precision_8: 0.6091 - recall_8: 0.7487 - val_loss: 0.1935 - val_accuracy: 0.7018 - val_precision_8: 0.6075 - val_recall_8: 0.7676\n","\n","Epoch 00144: val_loss did not improve from 0.18787\n","Epoch 145/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1922 - accuracy: 0.6988 - precision_8: 0.6106 - recall_8: 0.7429 - val_loss: 0.1940 - val_accuracy: 0.7007 - val_precision_8: 0.6049 - val_recall_8: 0.7754\n","\n","Epoch 00145: val_loss did not improve from 0.18787\n","Epoch 146/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1925 - accuracy: 0.7010 - precision_8: 0.6118 - recall_8: 0.7330 - val_loss: 0.1886 - val_accuracy: 0.7094 - val_precision_8: 0.6330 - val_recall_8: 0.6907\n","\n","Epoch 00146: val_loss did not improve from 0.18787\n","Epoch 147/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1922 - accuracy: 0.6995 - precision_8: 0.6124 - recall_8: 0.7402 - val_loss: 0.1920 - val_accuracy: 0.7019 - val_precision_8: 0.6099 - val_recall_8: 0.7545\n","\n","Epoch 00147: val_loss did not improve from 0.18787\n","Epoch 148/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1938 - accuracy: 0.6942 - precision_8: 0.6041 - recall_8: 0.7357 - val_loss: 0.1889 - val_accuracy: 0.7093 - val_precision_8: 0.6301 - val_recall_8: 0.7022\n","\n","Epoch 00148: val_loss did not improve from 0.18787\n","Epoch 149/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1941 - accuracy: 0.6963 - precision_8: 0.6087 - recall_8: 0.7307 - val_loss: 0.1904 - val_accuracy: 0.7078 - val_precision_8: 0.6213 - val_recall_8: 0.7332\n","\n","Epoch 00149: val_loss did not improve from 0.18787\n","Epoch 150/150\n","598/598 [==============================] - 2s 3ms/step - loss: 0.1926 - accuracy: 0.7005 - precision_8: 0.6134 - recall_8: 0.7397 - val_loss: 0.1944 - val_accuracy: 0.6988 - val_precision_8: 0.6018 - val_recall_8: 0.7816\n","\n","Epoch 00150: val_loss did not improve from 0.18787\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy: 0.6932426643820947\n","Recall: 0.5982332155477031\n","Specificity: 0.7720521172638436\n"],"name":"stdout"}]}]}